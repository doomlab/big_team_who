---
title             : "Who does big team science?"
shorttitle        : "Big Team Science"
author: 
  - name          : "Erin M. Buchanan"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "326 Market St., Harrisburg, PA 17101"
    email         : "ebuchanan@harrisburgu.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Data curation
      - Formal Analysis
      - Methodology
      - Project administration
      - Visualization
      - Writing – original draft
      - Writing – review & editing
  - name          : "Savannah C. Lewis"
    affiliation   : "2"
    role:
      - Conceptualization
      - Data curation
      - Methodology
      - Project administration
      - Writing – original draft
      - Writing – review & editing
affiliation:
  - id            : "1"
    institution   : "Harrisburg University of Science and Technology"
  - id            : "2"
    institution   : "University of Alabama"
authornote: |
  Erin M. Buchanan is a Professor of Cognitive Analytics at Harrisburg University of Science and Technology. Savannah C. Lewis is a graduate student at the University of Alabama.  
  
  Thank you to Dwayne Lieck for providing an extensive list of large scale projects for this manuscript. 
  
  Preprint: https://osf.io/hqta4/
abstract: |
  This paper examined the nature of publications in Big Team Science (BTS): large-scale collaborations between multiple researchers at multiple institutions. These projects can improve research by initiating collaborations that span across the globe, age groups, education levels, and subfields of research. As the number of BTS publications increase, it is useful to explore who is currently involved in BTS projects to determine diversity in both research subject and researcher representation. We examined the diversity of BTS publications and authors across more than half a million articles to investigate where and what is currently published, and author characteristics including differences in career length, publication metrics, affiliation, and affiliation geopolitical regions. Interestingly, BTS publications are increasingly dominated by early career researchers from WEIRD geopolitical regions with Health and Physical Science accounting for the majority of BTS articles. However, the increase in preprints, BTS articles, and non-WEIRD authors across time demonstrate the efforts of the science community to diversify its researchers. 
  
    Significance statement: This work is the first to examine big team science authorship (i.e., 10+ authors) across millions of published works. Big teams can provide high-impact, important research within scientific publishing, and this report suggests a promising trend of increasing numbers of publications that increasingly represent earlier career and varied scholars. The number of geopolitical entities for researcher affiliation is increasing over time, showing the results of globalization and the ability to connect across time zones and cultures. While publications are generally diversifying, we did not yet find equality in the representation for first or corresponding authors. First authors appear to be less diverse, representing more European and North American authors, while other authors include more Asian and African authors. 
  
  # General Disclosures
  
  Conflicts of interest: Both authors declare no conflicts of interest. 
  
  Funding: No funding was obtained for this project. 
  
  Artificial intelligence: No AI resources were used for this manuscript. 
  
  Ethics: No ethics review was necessary for this project. 
  
  Computational reproducibility: All materials and code can be found on our OSF page: https://osf.io/cgx6u/ or corresponding GitHub archive: https://github.com/doomlab/big_team_who. Elsevier has agreed to provide access to determine reproducibility of the code for accessing and summarizing articles, and the reproducible manuscript has been provided for review.
  
  Pre-registration: This manuscript was preregistered with the same conceptual ideas using Google Scholar and ORC-ID databases (https://osf.io/f2dtr) but then was updated with access to the Scopus database for a broader picture of BTS projects (https://osf.io/fheun). 
  
  Materials, Data, Analysis Scripts: All materials and code can be found on our OSF page: https://osf.io/cgx6u/ or corresponding GitHub archive: https://github.com/doomlab/big_team_who.
  
keywords          : "big team, science, authorship, credit"
floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
classoption       : "man"
editor_options: 
  markdown: 
    wrap: 72
  chunk_output_type: inline
bibliography: references.bib
appendix          :
  - "appendix.Rmd"
  
header-includes:
  - |
    \makeatletter
    \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-1em}%
      {\normalfont\normalsize\bfseries\typesectitle}}
    
    \renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-\z@\relax}%
      {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
    \makeatother

csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
documentclass     : "apa7"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
knitr::opts_knit$set(echo = FALSE, warning = FALSE, message = FALSE, include = FALSE, error = FALSE)
library(papaja)
library(knitr)
library(ggplot2)
library(treemapify)
library(countrycode)
library(rio)
library(maps)
library(dplyr)
library(tidyr)
library(MOTE)
library(MBESS)
library(patchwork)
library(ggplot2)
library(ggwordcloud)
library(figpatch)
library(RColorBrewer)
library(latex2exp)
library(patchwork)
library(broom)
library(minpack.lm)

options(scipen = 99)

strip_labels <- expression(
  "M Coefficient " = b[M],
  "SD Coefficient" = b[SD],
  "Effect Size" = R^2,
  "Coefficient" = b
)

label_expressions <- function(values) {
  stopifnot(is.expression(values))
  as_labeller(function(x) {
    if (is.null(names(values))) {
      x <- seq_along(x)
      if (length(x)!=length(values)) warning(paste0("Number of labels(", 
        length(values), ") does not match number of values (", length(x), ")"))
    }
    as.list(values[x])
  }, default = identity)
}

# things to import
var_list <- c("author_stats", "paper_stats", "author_paper_year",
              "career_time")

var_list_import <- paste0("data/scopus_outputs_2/", var_list, ".xlsx")

DF <- lapply(var_list_import, import)
names(DF) <- var_list
```

outline:

-   what is team science / collaboration
-   research on how it's grown / changed over time?
-   Any research diversification?
    -   on who is publishing
    -   on where is represented
-   "big" teams - unanswered question ... people are now using term "big
    team" but it's not defined - can we define it and see if it's any
    different or just a product of growth/internet over time?

SAVS NEW VERSION!

Collaboration in scientific endeavors involves multiple researchers at
(potentially) multiple institutions to communicate and work together to
advance knowledge in their chosen field. Collaboration can manifest
uniquely in each project dependent on the skill sets, hypotheses, and
perspectives of collaborators. One key aspect of collaboration is the
flexibility allotted as it is shaped by the needs of the project and the
participants involved.

While collaboration is not new in science, interest in "team science" is
growing as individual researchers seek an interdisciplinary approach to
research or bring on more students to their project. Unlike general
collaboration, team science involves structured roles, coordinated
workflows, and shared resources to address challenges that would be
difficult for individual researchers or one small team to solve
independently. Team science often brings in some aspect of diversity but
likely is still very homogenous in several aspects.

The evolution of team science reflects broader shifts in research
practices, driven by two sources: 1) increasing globalization and
technology that allows for real-time interdisciplinary research, and 2)
expanding interest in reproducibility, replication, and generalizability
[i.e., the credibility movement, @maxwell2015; @nelson2018; @zwaan2018;
@vazire2022]. Technological advances have provided easier ways to
collaborate with people who are from other universities and countries
through document sharing platforms (e.g., Google, GitHub, and the Open
Science Framework), video chatting platforms (e.g., Zoom, Microsoft
Teams), and messaging and project management platforms (e.g., Slack,
Trello, when2meet, etc.).

The credibility movement has been the main catalyst for the increased
interest and broader shift of research practices. The movement
emphasizes reproducibility and transparency in science, encouraging
researchers to form new ways to increase the rigor in scientific
endeavors. As the movement has adapted throughout the last decade, the
idea to form larger, more diverse teams and to include participants from
varied backgrounds has become even more a goal to not only increase the
credibility but the generalizability and reliability of scientific
findings. This form of collaboration has been coined “Big Team Science.”

“Big Team Science” builds on team science by scaling efforts to include
larger, often globally diverse teams, which requires significant
coordination and infrastructure [@coles2022; @forscher2022a;
@stewart2017]. BTS projects and organizations organize extensive
collaborations, intentionally incorporating diverse populations and
perspectives into research. This large-scale approach enhances the
reliability and generalizability of findings by integrating varied
methodologies and viewpoints, leading to more robust and inclusive
scientific outcomes. BTS organizations often pool extensive networks of
researchers and resources, aiming to tackle grand scientific challenges
that would be difficult to address within smaller or less coordinated
collaborations. By having both collaborations that span across the globe
and subfields of research areas, age groups, and education levels should
help to drive science in the path of better materials, reliability,
generalizability, and more robust sample sizes (when necessary) in a
study [@auspurg2021; @nosek2014method; @lebel2018].

Generally, the credibility movement appears to have been driven by early
career researchers [i.e., those who are within five years of their first
appointment, @maizey2019]; however, there are no large meta-scientific
investigations on this specific topic to date. The newness of
large-scale research in many fields could be the culprit for the lack of
investigation into this area. For example, psychology has had an
increase in BTS publications like the Open Science Collaboration
[@opensciencecollaboration2015], Many Labs Collaborations
[@buttrick2020; @ebersole2016; @ebersole2020; @klein2018; @klein2022;
@mathur2020; @skorb2020] or the first papers from the Psychological
Science Accelerator [@bago2022; @buchanan2023; @dorison2022; @jones2021;
@psychologicalscienceacceleratorself-determinationtheorycollaboration2022;
@moshontz2018; @wang2021]. Generally, the researcher incentive for
replication and/or involvement in big-team projects was low for three
reasons. First, journals often prioritize "novel" or new results which
led to rejection of replication manuscripts and publication bias
[@franco2014; @hubbard1997; @nosek2012]. Second, the "failure" to
replicate was often placed on the replication team as "bad science"
rather than a careful consideration of publication biases and
(potential) questionable research practices [@klein2022; @maxwell2015].
Last, why should someone want to spend time and resources on an answer
we already "know" [@isager2021; @isager2021a]?

However, the success and interest in the large-scale reproducibility
projects [@opensciencecollaboration2015; @10.7554/eLife.71601], paired
with the meta-scientific publications focusing on researcher practices
and incentive structures [@silberzahn2018many; @john2012] led to a
change in journal guidelines and incentives for researchers interested
in participating in large-scale replication studies [@grahe2014;
@kidwell2016; @nosek2015; @mayo-wilson2021]. In some fields, the
replication movement demonstrated that large-scale teams were a
practical (and publishable) solution to answering research questions in
generalizable way. The support for Registered Reports, papers accepted
before the data has been collected [@nosek2014; @stewart2020], has
allowed researchers to invest in projects that they know should be
published when the project is complete. Further, the implementation of
the Transparency and Openness Guidelines [@nosek2015] and the
Contributor Role Taxonomy (CRediT) system [@allen2019] have pushed
journals and researchers to promote more open, inclusive publication
practices.

Beyond replication concerns, the credibility movement has mirrored calls
for diversification or de-WEIRDing (e.g., Western, Educated,
Industrialized, Rich, and Democratic) scientific research [@henrich2010;
@newson2021; @rad2018] by improving representation in research samples.
Like the large-scale studies in Physics [@aphilos2021; @castelnovo2018]
and Biology [@collins2003], the Social Sciences struggle to represent
the breadth of humanity across both researcher and population
characteristics. Now, grassroots organizations, such as the
Psychological Science Accelerator [@moshontz2018], ManyBabies
(<https://manybabies.github.io/>), NutNet (<https://nutnet.org/>), and
DRAGNet (<https://dragnetglobal.weebly.com/>) can begin to tackle these
issues by recruiting research labs from all over the globe to provide
diversity in geographic, linguistic, and researcher representation.
Publications have examined the global understanding of morality, face
processing, COVID-19 information signaling, and more [@bago2022;
@dorison2022; @jones2021;
@psychologicalscienceacceleratorself-determinationtheorycollaboration2022;
@vanbavel2022; @wang2021]. While these organizations and one-time groups
for BTS studies have provided an incredible wealth of data for the
scientific community, we do not yet know exactly *who* is involved with,
and benefits from, the BTS and credibility movement. Publications on BTS
generally explore challenges, lessons learned, and the need for BTS
[@forscher2022a; @coles2022].

There is no universally agreed-upon definition of BTS, raising questions
about whether it represents a distinct phenomenon or simply a natural
extension of team science. Therefore, we originally arbitrarily chose a
definition for BTS publication which we had decided to be publications
with at least ten authors at ten different institutions that were
published in peer-reviewed journals or had posted a full paper
pre-print. While this definition is a somewhat arbitrary choice, we
separate this research from research on team science that uses any
multi-university collaboration as a definition [@jones2008] to focus on
larger sized teams rather than teams of any size. With at least ten
institutions, the complexities of infrastructure, resources, tenure and
promotion policies, ethics review, and more can occur [@forscher2022a].
Therefore, we believe this choice selects publications that would be
"big" teams and those potential obstacles.

<<<<<<< Updated upstream
This manuscript seeks not only to evaluate whether this definition is an
appropriate fit for BTS but also to explore whether the criteria for
defining BTS should vary by subject area or evolve over time.
Understanding these nuances will help clarify whether BTS represents a
fundamentally new approach to collaboration or a natural progression of
team science in response to global and technological trends.
=======
This manuscript seeks not only to evaluate whether this definition is an appropriate fit for BTS but also to explore whether the criteria for defining BTS should vary by subject area or evolve over time. Understanding these nuances will help clarify whether BTS represents a fundamentally new approach to collaboration or a natural progression of team science in response to global and technological trends. 

We then will examine if there is a true difference between “Team Science” and "Big Team Science”. Therefore, the goal of this manuscript is to examine both the *publications* and *people* involved in BTS projects and “Team Science.” We present descriptive information about the publication sources and types of articles to demonstrate large-scale research. Next, we examine the individuals involved in BTS and “Team Science” for descriptive and predictive purposes. To describe the people involved in BTS projects vs “Team Science”, we planned to use types of publications from individuals. For predictive statistics, we explored the change in diversity of authors over time. It is unclear if the focus of de-WEIRDing science has only focused on the representation of the research participants or if it has also improved the representation of researchers outside of North America and Europe. Last, we examined for a change in diversity within first author(s) and the last author across time. As hiring and promoting practices often place a heavy weight on publications and especially “influential” publications, it becomes necessary to critically examine the representation present in authorship in BTS and Team Science” projects. 
>>>>>>> Stashed changes

We then will examine if there is a true difference between “Team
Science” and "Big Team Science”. Therefore, the goal of this manuscript
is to examine both the *publications* and *people* involved in BTS
projects and “Team Science.” We present descriptive information about
the publication sources and types of articles to demonstrate large-scale
research. Next, we examine the individuals involved in BTS and “Team
Science” for descriptive and predictive purposes. To describe the people
involved in BTS projects vs “Team Science”, we planned to use types of
publications from individuals. For predictive statistics, we explored
the change in diversity of authors over time. It is unclear if the focus
of de-WEIRDing science has only focused on the representation of the
research participants or if it has also improved the representation of
researchers outside of North America and Europe. Last, we examined for a
change in diversity within first author(s) and the last author across
time. As hiring and promoting practices often place a heavy weight on
publications and especially “influential” publications, it becomes
necessary to critically examine the representation present in authorship
in BTS and Team Science” projects.

# Research Questions

- Research Question 1: Exploring historical and current publication
    values, what should define big team science versus team science?
  - Question 1A: What number of authors and institutional affiliations
    should designate the differences between team science and big team
    science?
  - Question 1B: Using the definition from 1A, are there changes in the
    number of publications over time?
- Research Question 2: How has the diversity of those involved in big
    team science versus team science changed over time?

# Method

## Publications

We used data from 1970-2024 in the Scopus database, as it is noted
online that 1970 and forward includes cited references for calculation
of several of our variables described below. We analyzed our results
based on four subject areas present in the Scopus database: Physical
Sciences, Health Sciences, Social Sciences, and Life Sciences. We
filtered the database to include articles, articles in press, business
articles, conference papers, data papers, preprints, and surveys using
Elsevier's classification system. This project was supported by access
to the Scopus database through the International Center for the Study of
Research.

## Data Curation

### RQ1: Defining BTS

For each of the publications in Scopus, we calculated the number of
distinct authors and institutions. If an author had multiple
affiliations, we used the first affiliation listed. Each publication was
classified into the four subject areas based on the All Journal Subject
Codes present in the database. Publications can be included in multiple
subject codes. For example, a medical paper may be listed in both life
sciences and health sciences.

### RQ2: Author Diversity Statistics

#### Seniority

Career length for each author was defined as the year of the first
publication minus the current year listed for each author. Number of
publications included the number of unique entries an author was
included in the database. Career length and number of publications was
used as a proxy for the "age" or "seniority" of a scholar.

#### Geopolitical Region

Geopolitical region was created by binning country code identifiers into
the 17 identified United Nation subregions.

# Results

We used the 95% confidence interval to make decisions on predictor or
effect size differences from zero. The confidence interval that does not
include zero would be considered different from zero (to four decimal
places). We made no directional predictions.

## RQ1A: Defining BTS

```{r total-papers}
total_papers <- 97532104 # the entire database
total_papers_past1970 <- 62966549 # past 1970, in our article types
distinct_authors_past1970 <- 53622443 # all authors 

# one row per author per paper with all authors with at least two  
team_author_aff_combo <- 196835398
team_author_aff_papers <- 32454393
team_author_aff_author <- 28353445

team_author_aff_subject_noNA <- 241269297
team_author_aff_papers_noNA <- 32448373
team_author_aff_author_noNA <- 28350468
```

The total number of papers included in the Scopus database at the time
of this analysis was `r total_papers`. `r total_papers_past1970`
articles were included past 1970 in the defined article types, which
included `r distinct_authors_past1970` distinct authors. We then
filtered the data to include only teams, which was defined as two
authors from at least two institutions. The total number of papers for
team projects was `r team_author_aff_papers` and
`r team_author_aff_author` distinct authors. The data was then
classified into subject areas by paper, which lead to missing data. The
final number of papers included was `r team_author_aff_papers_noNA` with
`r team_author_aff_author_noNA` distinct authors. The dataset was
curated to include one row per author, paper, and subject area (i.e.,
long format [@wickham2007]) which included `r team_author_aff_subject_noNA` total rows of data. For analyses and descriptive statistics below, we include sample sizes for clarity. 

```{r stats-authors-fig, include = F, fig.cap="The left panel depicts the number of authors included on a paper by subject area, and the right panel demonstrates the number of affiliations by subject area. The boxplot shows the median (bold line), the interquartile range (the box), and the minimum to the 90th percentile of the number of authors/affiliations as the range line. Normally these plots include the entire range of the data, but these extreme range made the boxplot information unreadable. The dots indicate the average number of authors/affiliations for each area with the size of the dot indicating the standard deviation of the statistic. Therefore, larger dots indicate more variability in the number of authors and affiliations. "}
temp_graph <- DF$author_stats %>% 
  filter(SubjectArea != "Multidisciplinary")

auth_plot <- 
  ggplot(temp_graph, aes(x = SubjectArea)) + 
  geom_boxplot(
    aes(
      ymin = Min_Num_Authors,
      lower = lower_IQR,
      middle = Med_Num_Authors,
      upper = upper_IQR,
      ymax = very_high_90
    ),
    stat = "identity"
  ) + 
  theme_bw() + 
  xlab("Subject Area") + 
  ylab("Number of Authors") +
  coord_cartesian(ylim = c(0,12)) + 
  scale_y_continuous(breaks = c(0,2,4,6,8,10,12)) +
  geom_point(aes(x = SubjectArea, y = Average_Num_Authors, 
                 size = SD_Num_Authors)) +
  theme(legend.position = "none")

aff_plot <- 
  ggplot(temp_graph, aes(x = SubjectArea)) + 
  geom_boxplot(
    aes(
      ymin = Min_Num_Aff,
      lower = lower_IQR_Aff,
      middle = Med_Num_Aff,
      upper = upper_IQR_Aff,
      ymax = very_high_90_Aff
    ),
    stat = "identity"
  ) + 
  theme_bw() + 
  xlab("Subject Area") + 
  ylab("Number of First Affiliations") +
  coord_cartesian(ylim = c(0,12)) + 
  scale_y_continuous(breaks = c(0,2,4,6,8,10,12)) +
  geom_point(aes(x = SubjectArea, y = Average_Num_Aff, 
               size = SD_Num_Authors)) +
  theme(legend.position = "none")


auth_plot | aff_plot
```

\@ref(fig:stats-authors-fig) displays the number of authors and affiliations by subject area. The figure demonstrates that the median number of authors is largest for health sciences, followed by life science, physical sciences, and then social sciences. The general pattern of team authorship includes about 2-8 authors, from about 2-4 institutions. We used the maximum (i.e., across all subject areas) 90th percentile as our exploratory definition for big team papers after examining the results from this analysis. We selected this percentile to have the high of the distribution, but also to be able to include enough papers for analysis across time. Therefore, big teams were defined as 11 authors from at least 6 different institutions[^In a previous version of this manuscript, we defined big teams as 10 authors from at least 10 institutions based on our own experiences working with research consortium. All definitions are likely subjective, but the definition in this manuscript represents the top 10% of author and affiliations in a large body of papers].

NEED TO RUN ALL TEAMS SUBJECT AREA GRAPH

```{r big-teams-table, results = 'asis'}
big_teams_papers <- 968765
big_teams_authors <- 4541369

apa_table(DF$paper_stats %>% 
        arrange(Statistic), 
        caption = "Number of Authors and Papers by Subject Area",
        note = "Papers can be classified into multiple categories.", 
        align = c("l", rep("c", 5)), 
        digits = 0)
```

\@ref(tab:big-teams-table) includes the number of distinct authors and papers for each subject area by overall teams and big teams using our 90th percentile definition. The total number of distinct authors for big team papers was `r big_teams_papers` with `r big_teams_authors` distinct authors. In RQ2, we split the big team data into small (6-10), medium, and large big team grouping for convenience to display/analyze geopolitical regions. The table shows the number of authors and papers for those analyses. 

## RQ1B: Changes over Time

SEE IF YOU CAN GET ALL THE NUMBERS SOME ARE MISSING

For analyzing changes across time, we split the data into regular teams (2-10 authors, 2-5 affiliations) and big teams (as defined above, 11+ authors, 6+ affiliations). The number of papers found in Scopus across time for each subject area are displayed in Figure \@ref(paper-time-fig). The visual results indicated that the number of regular team papers was increasing the most in physical sciences for all manuscripts, followed by life and health sciences, and the last is social sciences. Examining only big teams shows that the rate is also increasing across time. All teams appear to start increasing in the 1990s, while big teams do not start increasing off floor effects until past 2000. The health and life sciences show the largest increases across time in big teams with the smallest trend in the social sciences. 

```{r paper-time-fig, include = F, fig.cap = "The number of manuscripts across time for all team science papers (left) and big team science papers (right)."}
temp <- DF$author_paper_year %>% 
  filter(SubjectArea != "Multidisciplinary") %>% 
  filter(Year < 2024) %>% 
  mutate(SubjectArea = gsub("Sciences", "", SubjectArea))

# temp %>% 
#   group_by(SubjectArea, Year, group) %>% 
#   summarize(n = n())

p1 <- ggplot(temp %>% 
         filter(group == "regular"), 
         aes(x = Year, y = Number_Papers, 
             colour = SubjectArea)) + 
  geom_point() + 
  theme_minimal() + 
  scale_color_discrete(name = "Subject Area") + 
  theme(legend.position = "bottom",
        axis.text.y = element_text(angle = 45, hjust = 1)) + # Angles the y-axis text
  ylab("Number of Papers") + 
  ggtitle("Regular Teams")

p2 <- ggplot(temp %>% 
         filter(group == "big"), 
         aes(x = Year, y = Number_Papers, 
             colour = SubjectArea)) + 
  geom_point() + 
  theme_minimal() + 
  scale_color_discrete(name = "Subject Area") + 
  theme(legend.position = "bottom",
        axis.text.y = element_text(angle = 45, hjust = 1)) + # Angles the y-axis text
  ylab(NULL) +  # Removes the y-axis label
  ggtitle("Big Teams")

combined_plot <- p1 + p2 +
  plot_layout(guides = "collect") & # Collect shared legend
  theme(legend.position = "bottom")  # Center the legend at the bottom

combined_plot
```

```{r rate-estimates-fig, include = F, fig.cap = "Exponential growth rate estimates with 95% confidence intervals."}
# Initialize the results list
corr.results <- list()

# Ensure 'group' and 'subjarea' are defined
group <- unique(temp$group)
subjarea <- unique(temp$SubjectArea)

# Loop through groups and subject areas
for (group_label in group) {
  for (SA in subjarea) {
    stuff <- temp %>%
      filter(group == group_label) %>%
      filter(SubjectArea == SA)
    
    if (nrow(stuff) < 3 || any(stuff$Number_Papers <= 0)) {
      message("Skipping ", group_label, " - ", SA, ": insufficient or invalid data")
      next
    }
    
    # Calculate starting values
    a_start <- mean(stuff$Number_Papers, na.rm = TRUE)
    log_y <- log(stuff$Number_Papers)
    b_start <- coef(lm(log_y ~ stuff$Year))[2]
    
    tryCatch({
      fit <- nlsLM(
        Number_Papers ~ a * exp(b * Year), 
        data = stuff, 
        start = list(a = a_start, b = b_start)
      )
      corr.results[[paste0(group_label, "_", SA)]] <- tidy(fit)
    }, error = function(e) {
      message("Fit failed for ", group_label, " - ", SA, ": ", e$message)
    })
  }
}

corr.DF <- bind_rows(corr.results) %>% 
  mutate(group = rep(group, each = 8)) %>% 
  mutate(SubjectArea = c(
    rep(subjarea, each = 2),
    rep(subjarea, each = 2)
    )) %>% 
  filter(term != "a") %>% 
  mutate(conf.low = estimate-2*std.error,
         conf.high = estimate+2*std.error)

ggplot(corr.DF, aes(x = SubjectArea, y = estimate, color = group)) + 
  geom_point() +
  theme_minimal() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high),
                width = .2) + 
  ylab("Rate Estimate") + 
  xlab("Subject Area") + 
  scale_color_discrete(name = "Team Size", 
                       labels = c("Big", "Regular")) + 
  theme(legend.position = "bottom") + 
  geom_hline(yintercept = 0)
```

Using the `minpack.lm` library [CITE ME], we calculated the exponential rate of growth for regular teams and big teams, and these results are shown in \@ref(fig:rate-estimates-fig). All growth rate confidence intervals excluded zero, indicating an exponential increase in the number of team papers over time. Big team growth rates were always higher than their regular team counterparts, but the 95% confidence intervals for the growth estimate overlapped for all statistics. Therefore, the growth trends, while visually appearing to be different, were likely similar for each subject area and team size when examined by estimating exponential growth statistics. 

## RQ2: Diversity Statistics

### Seniority

Figure \@ref(fig:fig-career) portrays the average career length for
authors involved in BTS publications across years. Career length was
defined as the year of first publication minus the current year, and
higher numbers mean longer careers. To analyze trends over time, we
calculated the average career length for each publication (i.e., averaging author career lengths to create one score for each paper) and analyzed a
regression analysis using career length to predict year of publication.
In order to show variance between individuals, we calculated the
standard deviation of career length for each publication and used this
variance as an additional predictor.

Negative career length slopes would indicate more young scholars in
later years (i.e., lower average career length as time increases).
Positive career length slopes would indicate older scholars in later
years (i.e., higher average career length as time increases). Negative
career variance slopes imply that variability decreases over the years,
so the average career length is more homogeneous. Positive career length
slopes imply that variability increases over the years, so the average
career length is varied across individuals (i.e., different stages of
scholars). Figure \@ref(fig:fig-heatmap) displays the results for all
regression analyses to compare coefficient strength across and within
each hypothesis.

### Edit me

All values for these analyses were different from zero. The slopes for
the average career length were negative for all four subject areas,
indicating a trend toward younger scientist involvement over time for
each area, with the strongest effect in the Physical Sciences. The
coefficient for variability in career length was also negative for each
of the four subject areas with the highest in the Physical Sciences and
lowest in the Life Sciences. This result indicates a decrease in the
variability of career lengths over time, likely from two sources: 1)
more publications with more authors, thus, lowering variance
estimations, and 2) more young scholars overall. The effect sizes for
this analysis were surprisingly large ranging from $R^2$ = .25 to .47.
All values and their confidence intervals can be found on our OSF page.

-   four panel figure for subject area by total team, "team", BAT
-   just in general people are having to publish much younger than we
    used to so here's how to view that

```{r fig-career, include = TRUE,  warning = FALSE, message = FALSE, fig.cap = "Average career length for big-team science authors. Larger dots indicate more variability in career length for authors by averaging the standard deviation in career length for each manuscript within a year. The data has been filtered to at least 10 publications in a year for this graph.", fig.width=10, fig.height=6}
ggplot(DF$career_time %>% 
         filter(SubjectArea != "Multidisciplinary") %>% 
         filter(num_papers >= 10) %>% 
         filter(Year < 2024) %>% 
         mutate(Team = factor(Team, 
                              levels = c("Regular", "Big"))), 
       aes(Year, avg_career, color = Team)) +
  theme_classic(base_size = 15) + 
  geom_point(aes(size = sd_career)) +
  # geom_point() + 
  facet_wrap(~SubjectArea) + 
  theme(legend.position = "bottom") + 
  ylab("Average Career Length") +
  xlab("Year of Publication") + 
  scale_color_brewer(palette = "Dark2", name = "Subject Area") +
  guides(size = "none")  
  #scale_size_continuous(name = "Number Papers")

ggsave(filename = "figure/figure_4_career.png", width = 10, height = 6)
```

```{r career-results, include = FALSE}

label <- c("Physical", "Social", "Health", "Life")
avg_b_values <- c(-0.692014, -0.365357, -0.451827, -0.508350)
avg_se_values <- c(0.002727, 0.005525, 0.001348, 0.001786)
sd_b_values <- c(-0.265538, -0.097108, -0.096730, -0.013958)
sd_se_values <- c(0.007018, 0.013409, 0.003451, 0.004523)
r2_values <- c(0.465446, 0.254312, 0.303781, 0.350923)
sample_size <- total_num

r2_low <- 1:length(r2_values)
r2_high <- 1:length(r2_values)
for (i in 1:length(r2_values)){
  temp <- ci.R2(R2 = r2_values[i], 1, sample_size)
  r2_low[i] <- temp$Lower.Conf.Limit.R2
  r2_high[i] <- temp$Upper.Conf.Limit.R2
}

graph_data <- data.frame(
  "label" = label,
  "estimate" = avg_b_values,
  "type" = "Coefficient",
  "low" = avg_b_values - qt(.025, sample_size, lower.tail = F)*avg_se_values,
  "high" = avg_b_values + qt(.025, sample_size, lower.tail = F)*avg_se_values) %>% 
    bind_rows(
    data.frame(
    "label" = label,
    "estimate" = sd_b_values,
    "type" = "SD Coefficient",
    "low" = sd_b_values - qt(.025, sample_size, lower.tail = F)*sd_se_values,
    "high" = sd_b_values + qt(.025, sample_size, lower.tail = F)*sd_se_values) 
    ) %>% 
  bind_rows(
    data.frame(  
      "label" = label, 
      "estimate" = r2_values,
      "type" = "Effect Size",
      "low" = r2_low,
      "high" = r2_high)
  )

graph_data$type <- factor(
  graph_data$type, 
  levels = c("Coefficient", "SD Coefficient", "Effect Size")
)

graph_data$analysis <- "Career"

# ggplot(graph_data, aes(label, estimate)) + 
#   geom_point() +
#   geom_pointrange(aes(ymin = low, ymax = high)) +
#   theme_classic() + 
#   facet_wrap(~type, labeller  = labeller(type = label_expressions(strip_labels))) + 
#   geom_hline(yintercept = 0) + 
#   coord_flip() + 
#   xlab("Subject Area") + 
#   ylab("")
```

```{r pub-results, include = FALSE}

label <- c("Physical", "Social", "Health", "Life")
avg_b_values <- c(0.004248, -0.027315, -0.021713, -0.009466)
avg_se_values <- c(0.000179, 0.001073, 0.000211, 0.000213)
sd_b_values <- c(-0.021552, 0.016810, 0.010139, -0.000378)
sd_se_values <- c(0.000241, 0.000921, 0.000198, 0.000235)
r2_values <- c(0.135965, 0.035968, 0.048999, 0.030748)
sample_size <- total_num

r2_low <- 1:length(r2_values)
r2_high <- 1:length(r2_values)
for (i in 1:length(r2_values)){
  temp <- ci.R2(R2 = r2_values[i], 1, sample_size)
  r2_low[i] <- temp$Lower.Conf.Limit.R2
  r2_high[i] <- temp$Upper.Conf.Limit.R2
}

graph_data_2 <- data.frame(
  "label" = label,
  "estimate" = avg_b_values,
  "type" = "Coefficient",
  "low" = avg_b_values - qt(.025, sample_size, lower.tail = F)*avg_se_values,
  "high" = avg_b_values + qt(.025, sample_size, lower.tail = F)*avg_se_values) %>% 
    bind_rows(
    data.frame(
    "label" = label,
    "estimate" = sd_b_values,
    "type" = "SD Coefficient",
    "low" = sd_b_values - qt(.025, sample_size, lower.tail = F)*sd_se_values,
    "high" = sd_b_values + qt(.025, sample_size, lower.tail = F)*sd_se_values) 
    ) %>% 
  bind_rows(
    data.frame(  
      "label" = label, 
      "estimate" = r2_values,
      "type" = "Effect Size",
      "low" = r2_low,
      "high" = r2_high)
  )

graph_data_2$type <- factor(
  graph_data_2$type, 
  levels = c("Coefficient", "SD Coefficient", "Effect Size")
)

graph_data_2$analysis <- "Publication"

# ggplot(graph_data, aes(label, estimate)) + 
#   geom_point() +
#   geom_pointrange(aes(ymin = low, ymax = high)) +
#   theme_classic() + 
#   facet_wrap(~type, labeller  = labeller(type = label_expressions(strip_labels))) + 
#   geom_hline(yintercept = 0) + 
#   coord_flip() + 
#   xlab("Subject Area") + 
#   ylab("")
```

```{r diversity-results, include = FALSE}

label <- c("Physical", "Social", "Health", "Life")
b_values <- c(0.002175, 0.033175, 0.016824, 0.008029)
se_values <- c(0.002578, 0.006039, 0.001150, 0.001476)
r2_values <- c(0.000006, 0.001542, 0.000708, 0.000170)
sample_size <- total_num

r2_low <- 1:length(r2_values)
r2_high <- 1:length(r2_values)
for (i in 1:length(r2_values)){
  temp <- ci.R2(R2 = r2_values[i], 1, sample_size)
  r2_low[i] <- temp$Lower.Conf.Limit.R2
  r2_high[i] <- temp$Upper.Conf.Limit.R2
}

graph_data_3 <- data.frame(
  "label" = label,
  "estimate" = b_values,
  "type" = "Coefficient",
  "low" = b_values - qt(.025, sample_size, lower.tail = F)*se_values,
  "high" = b_values + qt(.025, sample_size, lower.tail = F)*se_values) %>% 
  bind_rows(
    data.frame(  
      "label" = label, 
      "estimate" = r2_values,
      "type" = "Effect Size",
      "low" = r2_low,
      "high" = r2_high)
  )

graph_data_3$type <- factor(
  graph_data_3$type,
  levels = c("Coefficient", "Effect Size")
)

graph_data_3$analysis <- "Regions"

# ggplot(graph_data, aes(label, estimate)) + 
#   geom_point() +
#   geom_pointrange(aes(ymin = low, ymax = high)) +
#   theme_classic() + 
#   facet_wrap(~type, labeller  = labeller(type = label_expressions(strip_labels_2))) + 
#   geom_hline(yintercept = 0) + 
#   coord_flip() + 
#   xlab("Subject Area") + 
#   ylab("")
```

```{r fig-heatmap, include = TRUE, fig.cap="Heatmap results of regression analyses for career length, number of publications, and geopolitical diversity within the region. Each square represents a *b* value or the slope of the predictor (x-axis) onto the dependent variable (each panel), with the exception of the bottom row which is the effect size of each regression analysis $R^2$. Slopes included both the overall value of the predictor ($b$, $b_M$) and the standard deviation of the predictor over time ($b_{SD}$). The color of the square represents the strength of the predictor. The top figure represents all results together for comparison across analyses. The bottom row represents individual heatmaps for each hypothesis to distinguish small differences between subject areas for those research questions. Non-significant results are indicated with NS on the plot.", warning = FALSE, message = FALSE, fig.width=10, fig.height=6}
graph_overall <- graph_data %>% 
  bind_rows(graph_data_2) %>% 
  bind_rows(graph_data_3) %>% 
  mutate(type = factor(type, levels = c("Effect Size", "SD Coefficient", "Coefficient"))) %>% 
  mutate(Estimate = estimate) %>% 
  mutate(heat_label = ifelse(
    low < .00001 & high > .00001, "NS", ""
  ))
  
heat_results <- ggplot(graph_overall, aes(label, type, fill = Estimate)) + 
  geom_tile(color = "white", lwd = 1.5, linetype = 1) +
  coord_fixed() + 
  scale_y_discrete(labels  = c(TeX("$R^2$"), TeX("$b_{SD}$"), TeX("$b$"))) + 
  ylab("") + 
  xlab("") + 
  facet_wrap(~analysis) + 
  theme_classic(base_size = 15) + 
  theme(axis.text.x = element_text(angle = 60, vjust = .5), 
        legend.position = "right", 
        legend.key.size = unit(.75, 'cm')) + 
  scale_fill_distiller(palette = "Spectral") + 
  geom_text(aes(label=heat_label))


# heat_results

heat_results_1 <- ggplot(graph_overall %>% 
                           filter(analysis == "Career"), 
                         aes(label, type, fill = Estimate)) + 
  geom_tile(color = "white", lwd = 1.5, linetype = 1) +
  coord_fixed() + 
  scale_y_discrete(labels  = c(TeX("$R^2$"), TeX("$b_{SD}$"), TeX("$b_M$"))) + 
  ylab("") + 
  xlab("") + 
  theme_classic(base_size = 15) + 
  theme(axis.text.x = element_text(angle = 60, vjust = .5), 
        legend.position = "right") + 
  scale_fill_distiller(palette = "RdBu") + 
  ggtitle("Career")  + 
  geom_text(aes(label=heat_label))

heat_results_2 <- ggplot(graph_overall %>% 
                           filter(analysis == "Publication"), 
                         aes(label, type, fill = Estimate)) + 
  geom_tile(color = "white", lwd = 1.5, linetype = 1) +
  coord_fixed() + 
  scale_y_discrete(labels  = c(TeX("$R^2$"), TeX("$b_{SD}$"), TeX("$b_M$"))) + 
  ylab("") + 
  xlab("") + 
  theme_classic(base_size = 15) + 
  theme(axis.text.x = element_text(angle = 60, vjust = .5), 
        legend.position = "right") + 
  scale_fill_distiller(palette = "PuOr") + 
  ggtitle("Publication") + 
  geom_text(aes(label=heat_label))

heat_results_3 <- ggplot(graph_overall %>% 
                           filter(analysis == "Regions"), 
                         aes(label, type, fill = Estimate)) + 
  geom_tile(color = "white", lwd = 1.5, linetype = 1) +
  coord_fixed() + 
  scale_y_discrete(labels  = c(TeX("$R^2$"), TeX("$b$"))) + 
  ylab("") + 
  xlab("") + 
  theme_classic(base_size = 15) + 
  theme(axis.text.x = element_text(angle = 60, vjust = .5), 
        legend.position = "right") + 
  scale_fill_distiller(palette = "PiYG") +
  ggtitle("Regions") + 
  geom_text(aes(label=heat_label))

layout <- "
AAA
BCD
"
suppressMessages(suppressWarnings(heat_results + 
  heat_results_1 + heat_results_2 + heat_results_3 + 
  plot_layout(design = layout)))

ggsave(filename = "figure/figure_5_heatmap.png", width = 10, height = 6, units = "in")
```

We used the same analyses using number of publications to represent
diversity instead of career length. An increasing slope over time
indicates that individuals who are publishing more are more represented
in BTS over time (i.e., increasing numbers of scholars with higher
publication rates), while a negative slope indicates more researchers
with less publications. A positive slope for the standard deviation of
publication metrics indicates increasing variance over time (i.e., more
diversity in the individual publication rates), while a negative slope
would indicate less diversity in researchers over time. While
publication rates do not represent value as a researcher, they are often
used in hiring and promotion decisions, and we used this variable as a
proxy to gauge the diversity in scholars represented in big teams. As
shown in Figure \@ref(fig:fig-heatmap) publication metrics were
generally negative for the average publication metrics, indicating more
scholars over time with lower numbers of publications with the strongest
effects in Health and Social Sciences. The variability of publication
counts was not significant for the Life Sciences but was negative for
the Physical Sciences (less variability over time) and positive for
Social and Health Sciences (more variability and over time). This result
indicates that the Physical Sciences are trending toward scholars with
less publications but also less diverse in number of publications, while
the Health and Social Sciences see more diversity in publication counts
and less published scholars overall.

```{r geo-map}
# serbia has changed codes
# updated but needs work
DF$geo_country$affiliation_tag_country <- toupper(DF$geo_country$affiliation_tag_country)
DF$geo_country <- subset(DF$geo_country, affiliation_tag_country != "NONE")
DF$geo_country$affiliation_tag_country[DF$geo_country$affiliation_tag_country == "SCG"] <- "SRB"

DF$geo_country <- DF$geo_country %>% 
  group_by(affiliation_tag_country) %>% 
  summarize(count = sum(count),
            count_all = sum(all_count))

# convert country code to region code
# this will warn you about the ones that have multiple countries 
# create a world map 
world_map <- map_data(map = "world")
world_map$orig_region <- world_map$region
world_map$region <- iso.alpha(world_map$region, n = 3)
world_map <- subset(world_map, region != "ATA")
  
# maybe try binning
DF$geo_country$count_binned <- if_else(
  DF$geo_country$count >= 1000000, "1,000,000+", 
  if_else(
    DF$geo_country$count >= 500000 & DF$geo_country$count < 1000000, "500,000-999,999",
    if_else(
      DF$geo_country$count >= 100000 & DF$geo_country$count < 500000, "100,000-499,999",
      if_else(
        DF$geo_country$count >= 10000 & DF$geo_country$count < 100000, "10,000-99,999", 
        if_else(
          DF$geo_country$count < 10000 & DF$geo_country$count >= 5000, "5,000-9,999",
          if_else(
            DF$geo_country$count < 5000 & DF$geo_country$count >= 1000, "1,000-4,999",
            if_else(
              DF$geo_country$count < 1000 & DF$geo_country$count >= 100, "100-999",
              "< 100"
            )
          )
        )
      )
    )
  )
)

DF$geo_country$count_binned <- factor(DF$geo_country$count_binned, 
                                   levels = unique(DF$geo_country$count_binned))

DF$geo_country$count_binned <- factor(DF$geo_country$count_binned, 
                                      levels = c("< 100", 
                                                 "100-999", 
                                                 "1,000-4,999", 
                                                 "5,000-9,999", 
                                                 "10,000-99,999",
                                                 "100,000-499,999",
                                                 "500,000-999,999",
                                                 "1,000,000+"))

# map of binned data 
bin_country <- ggplot(DF$geo_country) +
  geom_map(aes(map_id = affiliation_tag_country, fill = count_binned), map = world_map) +
  geom_polygon(data = world_map, 
               aes(x = long, y = lat, group = group), 
               colour = 'black', fill = NA) + 
  theme_void(base_size = 15) + 
  # scale_fill_manual(name = "Sample Size",
  #                   values = c( "black", "#323232", "#646464","#969696","#c8c8c8")) 
  scale_fill_brewer(name = "Sample Size", palette = "Spectral", drop = FALSE)

# Warning: Some values were not matched unambiguously: ANT, ATA, BUR, BUX, BYS, CAI, CSK, CZH, DDR, EUE, HVO, PCI, ROM, SUN, SUX, TWN, UNO, YMD, YUG, ZAR

# tree map
DF$geo_country$un_region_sub <- suppressWarnings(
  countrycode(
  sourcevar = DF$geo_country$affiliation_tag_country,
  origin = 'iso3c', 
  destination = 'un.regionsub.name')
)

DF$geo_country$un_region <- suppressWarnings(
  countrycode(
  sourcevar = DF$geo_country$affiliation_tag_country,
  origin = 'iso3c', 
  destination = 'un.region.name')
)

DF$geo_country$un_region[DF$geo_country$affiliation_tag_country == "TWN"] <- "Asia"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "TWN"] <- "Eastern Asia"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "ANT"] <- "Western Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "BUR"] <- "Western Africa"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "BYS"] <- "Eastern Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "CSK"] <- "Eastern Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "DOR"] <- "Eastern Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "HVO"] <- "Sub-Saharan Africa"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "PCI"] <- "Eastern Asia"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "ROM"] <- "Eastern Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "SUN"] <- "Eastern Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "YMD"] <- "Western Asia"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "YUG"] <- "Eastern Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "ZAR"] <- "Sub-Saharan Africa"

DF$geo_country <- DF$geo_country %>% 
  na.omit()

tree <- ggplot(DF$geo_country, aes(area = count, fill = count_binned,
               label = affiliation_tag_country, subgroup = un_region_sub)) +
  geom_treemap() +
  geom_treemap_subgroup_border(colour = "white", size = 5) +
  # geom_treemap_subgroup_text(place = "top", grow = TRUE,
  #                            alpha = 0.25, colour = "black",
  #                            fontface = "italic") +
  geom_treemap_text(colour = "black", place = "centre",
                    size = 15, grow = FALSE) +  
  # scale_fill_manual(name = "Sample Size",
  #                   values = c("#c8c8c8", "#969696", "#646464", "#323232", "black")) 
  scale_fill_brewer(name = "Sample Size", palette = "Spectral", drop = FALSE)
  # scale_fill_gradient(name = "Sample Size",
  #                     low = "#c8c8c8", 
  #                     high = "#323232") 
```

```{r geo-map-all}
# maybe try binning
DF$geo_country$count_binned_all <- if_else(
  DF$geo_country$count_all >= 1000000, "1,000,000+", 
  if_else(
    DF$geo_country$count_all >= 500000 & DF$geo_country$count_all < 1000000, "500,000-999,999",
    if_else(
      DF$geo_country$count_all >= 100000 & DF$geo_country$count_all < 500000, "100,000-499,999",
      if_else(
        DF$geo_country$count_all >= 10000 & DF$geo_country$count_all < 100000, "10,000-99,999", 
        if_else(
          DF$geo_country$count_all < 10000 & DF$geo_country$count_all >= 5000, "5,000-9,999",
          if_else(
            DF$geo_country$count_all < 5000 & DF$geo_country$count_all >= 1000, "1,000-4,999",
            if_else(
              DF$geo_country$count_all < 1000 & DF$geo_country$count_all >= 100, "100-999",
              "< 100"
            )
          )
        )
      )
    )
  )
)

DF$geo_country$count_binned_all <- factor(DF$geo_country$count_binned_all, 
                                   levels = unique(DF$geo_country$count_binned_all))

DF$geo_country$count_binned_all <- factor(DF$geo_country$count_binned_all, 
                                      levels = c("< 100", 
                                                 "100-999", 
                                                 "1,000-4,999", 
                                                 "5,000-9,999", 
                                                 "10,000-99,999",
                                                 "100,000-499,999",
                                                 "500,000-999,999",
                                                 "1,000,000+"))

# map of binned data 
bin_country_all <- ggplot(DF$geo_country) +
  geom_map(aes(map_id = affiliation_tag_country, fill = count_binned_all), map = world_map) +
  geom_polygon(data = world_map, 
               aes(x = long, y = lat, group = group), 
               colour = 'black', fill = NA) + 
  theme_void(base_size = 15) + 
  # scale_fill_manual(name = "Sample Size",
  #                   values = c( "black", "#323232", "#646464","#969696","#c8c8c8")) 
  scale_fill_brewer(name = "Sample Size", palette = "Spectral", drop = FALSE)

tree_all <- ggplot(DF$geo_country, aes(area = count_all, fill = count_binned_all,
               label = affiliation_tag_country, subgroup = un_region_sub)) +
  geom_treemap() +
  geom_treemap_subgroup_border(colour = "white", size = 5) +
  # geom_treemap_subgroup_text(place = "top", grow = TRUE,
  #                            alpha = 0.25, colour = "black",
  #                            fontface = "italic") +
  geom_treemap_text(colour = "black", place = "centre",
                    size = 15, grow = FALSE) +  
  # scale_fill_manual(name = "Sample Size",
  #                   values = c("#c8c8c8", "#969696", "#646464", "#323232", "black")) 
  scale_fill_brewer(name = "Sample Size", palette = "Spectral", drop = FALSE)
  # scale_fill_gradient(name = "Sample Size",
  #                     low = "#c8c8c8", 
  #                     high = "#323232") 
```

```{r fig-map-both, include = TRUE, fig.cap="Geopolitical regions represented in big-team science publications versus all publications. The mosaic plot is grouped by UN subregion with the largest number of publications starting on the bottom left and smallest on the top right. Therefore, North America represents the largest number of authors within BTS (i.e., bottom right, then separated into the geopolitical areas within that subregion), followed by Eastern Europe (top left), and so on.", fig.width=10, fig.height=6}
bin_country + ggtitle("Big-Team Publication Map") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme(legend.position = "none") + 
tree + ggtitle("Big-Team Publication Mosiac Chart") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  guides(fill = "none") + 
bin_country_all + ggtitle("All Publications Map") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  guides(fill = "none") + 
tree_all + ggtitle("All Publications Mosiac Chart") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  guides(fill = "none") + 
  plot_layout(ncol = 2, 
              nrow = 2) + 
  plot_layout(guides = "collect") & theme(legend.position = 'bottom')

ggsave(filename = "figure/figure_6_map.png", width = 10, height = 6, units = "in")
```

### Geopolitical Regions

Author geopolitical region is displayed in Figure
\@ref(fig:fig-map-both). Big team publications appear to be led by North
America and Western Europe, while all publications are led by North
America and East Asia. To understand the change in representation
diversity, we examined if the number of regions in a publication is
predicted by the year of publication. Increasing diversity would be
represented by a positive slope, while decreasing diversity would be
represented by a negative slope. As shown in Figure
\@ref(fig:fig-heatmap), the Physical Sciences do not show a trend of
change in representation, while all other sciences showed a positive
effect increasing in the number of geopolitical regions authors
represent on publications.

Last, we examined the differences in representation for corresponding
author sets versus all other authors. For papers with 10 to 49 authors,
we used the three first authors and the last author to compare against
other authors. For 50 to 99 authors, five first authors plus last were
used, and for all papers with more than 100 authors, we used ten first
authors and the last author as the corresponding author set. We then
calculated the frequencies of each of the UN Sub-Regions for
corresponding authors versus all other authors, converting these values
to proportions. Given the expected small sample sizes of these
contingency tables, we grouped together titles based on the year of
publication. For each grouping, we then calculated the effect size of
the differences in frequencies comparing corresponding authors to all
other authors. Since this data is categorical, we used Cramer's *V* to
represent the effect size. If the effect size includes zero in its
confidence interval (to four decimal places), this result will imply
that first and all other authors represent the same pattern of UN
Sub-Region diversity. Any confidence interval that does include zero
represents a difference in diversity.

updated binning:

-   teams: 2-10 authors, 2-5 inst
    -   first and last author only versus everyone else
-   big ass teams: 6+ affs
    -   small: 11-49
        -   first three plus last versus everyone else
    -   medium: 50-99
        -   first five plus last versus everyone else
    -   large: 100+
        -   first 10 plus last versus everyone else

for time: teams versus big teams combining results separate panel of the
big teams separated (not by time)

```{r small-effects, warning = FALSE}
DF$small_first_gp <- DF$small_first_gp %>% 
  filter(aff_un != "other") %>% 
  pivot_wider(id_cols = Year, 
              names_from = aff_un, 
              values_from = count,
              values_fill = 0)

DF$small_other_gp <- DF$small_other_gp %>% 
  filter(aff_un != "other") %>% 
  pivot_wider(id_cols = Year, 
              names_from = aff_un, 
              values_from = count,
              values_fill = 0) %>% 
  select(colnames(DF$small_first_gp))

small_effect <- data.frame(
  year = 1:length(unique(DF$small_first_gp$Year)),
  v = 1:length(unique(DF$small_first_gp$Year)),
  low = 1:length(unique(DF$small_first_gp$Year)),
  high = 1:length(unique(DF$small_first_gp$Year))
)
i <- 1
for (year in unique(DF$small_first_gp$Year)){
  temp_table <- DF$small_first_gp %>% filter(Year == year) %>% select(-Year) %>% 
    bind_rows(DF$small_other_gp %>% filter(Year == year) %>% select(-Year))
  
  col_total <- colSums(temp_table)
  temp_table <- temp_table %>% 
    select(names(col_total)[col_total > 0])
  temp <- suppressWarnings(chisq.test(as.matrix(temp_table)))
  
  tryCatch(mote_temp <- v.chi.sq(x2 = temp$statistic, n = sum(temp_table), 
                        r = nrow(temp_table), c = ncol(temp_table), 
                        a = .05), 
       warning = function(w) { 
         mote_temp <<- v.chi.sq(x2 = temp$statistic, n = sum(temp_table), 
                        r = nrow(temp_table), c = ncol(temp_table), 
                        a = .05)
         mote_temp$vlow <<- 0
  }
  )
  
  small_effect$year[i] <- year
  small_effect$v[i] <- mote_temp$v
  small_effect$low[i] <- mote_temp$vlow
  small_effect$high[i] <- mote_temp$vhigh
  small_effect$people[i] <- mote_temp$n
  i <- i + 1
}

small_effect$high[is.na(small_effect$high)] <- 0
small_effect <- 
  small_effect %>% 
  filter(v != Inf)

small_dot <- ggplot(small_effect, aes(year,v)) + 
  geom_point(aes(size = people)) + 
  theme_classic(base_size = 15) + 
  geom_pointrange(aes(ymin = low, ymax = high)) + 
  xlab("Year") + 
  ylab(expression(phi)) + 
  scale_size_continuous(name = "Num Authors")

DF_decade <- DF$small_first_gp %>% 
  mutate(who = "F") %>% 
  bind_rows(
    DF$small_other_gp %>% 
      mutate(who = "O")
  ) %>% 
  mutate(Decade = ifelse(Year < 1990, "1980s", 
                         ifelse(Year < 2000, "1990s", 
                                ifelse(Year < 2010, "2000s", 
                                       ifelse(Year < 2020, "2010s", "2020s"))))) %>% 
  group_by(who, Decade) %>% 
  summarize_all(sum) %>% 
  pivot_longer(cols = -c(who, Decade, Year),
               names_to = "Country", 
               values_to = "Count")

# North America, Africa (combine), NWS Europe, Eastern Asia, Latin America, Rest of Europe, Rest of Asia, Everything Else 

DF_decade$Country_2 <- DF_decade$Country
DF_decade$Country_2 <- gsub(".*Africa.*", "Africa", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Northern Europe|Southern Europe|Western Europe", "NWS Europe", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("South-Eastern Europe|Eastern Europe", "ESE Europe", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Central Asia|South-Eastern Asia|Southern Asia|Western Asia", "Asia", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Melanesia|Mirconesia|New zealand and Australia|Polynesia", "Other", DF_decade$Country_2)

DF_decade$Country_2 <- factor(DF_decade$Country_2, 
                              levels = c("Africa", "Asia", "Eastern Asia", 
                                         "ESE Europe", 
                                         "Latin America and the Caribbean",
                                         "North America", 
                                         "NWS Europe", "Other"))
DF_decade_sm <- DF_decade %>% 
  group_by(Country_2, Decade, who) %>% 
  summarize(Count = sum(Count), .groups = "keep")

small_author <- ggplot(DF_decade_sm, aes(who, Count, fill = Country_2)) + 
    geom_bar(position="fill", stat="identity", color = "black") + 
  theme_classic(base_size = 15) + 
  facet_grid(~Decade) + 
  xlab("Author Type") + 
  ylab("Percent of Authors") + 
  scale_fill_brewer(name = "Region", palette = "Spectral", drop = FALSE)
```

```{r medium-effects, warning = FALSE}
DF$medium_first_gp <- DF$medium_first_gp %>% 
  filter(aff_un != "other") %>% 
  pivot_wider(id_cols = Year, 
              names_from = aff_un, 
              values_from = count,
              values_fill = 0)

DF$medium_other_gp <- DF$medium_other_gp %>% 
  filter(aff_un != "other") %>% 
  pivot_wider(id_cols = Year, 
              names_from = aff_un, 
              values_from = count,
              values_fill = 0) %>% 
  select(colnames(DF$medium_first_gp))

medium_effect <- data.frame(
  year = 1:length(unique(DF$medium_first_gp$Year)),
  v = 1:length(unique(DF$medium_first_gp$Year)),
  low = 1:length(unique(DF$medium_first_gp$Year)),
  high = 1:length(unique(DF$medium_first_gp$Year))
)
i <- 1
for (year in unique(DF$medium_first_gp$Year)){
  temp_table <- DF$medium_first_gp %>% filter(Year == year) %>% select(-Year) %>% 
    bind_rows(DF$medium_other_gp %>% filter(Year == year) %>% select(-Year))
  
  col_total <- colSums(temp_table)
  temp_table <- temp_table %>% 
    select(names(col_total)[col_total > 0])
  temp <- suppressWarnings(chisq.test(as.matrix(temp_table)))
  tryCatch(mote_temp <- v.chi.sq(x2 = temp$statistic, n = sum(temp_table), 
                        r = nrow(temp_table), c = ncol(temp_table), 
                        a = .05), 
       warning = function(w) { 
         mote_temp <<- v.chi.sq(x2 = temp$statistic, n = sum(temp_table), 
                        r = nrow(temp_table), c = ncol(temp_table), 
                        a = .05)
         mote_temp$vlow <<- 0
  }
  )
  medium_effect$year[i] <- year
  medium_effect$v[i] <- mote_temp$v
  medium_effect$low[i] <- mote_temp$vlow
  medium_effect$high[i] <- mote_temp$vhigh
  medium_effect$people[i] <- mote_temp$n
  i <- i + 1
}

medium_effect$high[is.na(medium_effect$high)] <- 0
medium_effect <- 
  medium_effect %>% 
  filter(v != Inf)

medium_dot <- ggplot(medium_effect, aes(year,v)) + 
  geom_point(aes(size = people)) + 
  theme_classic(base_size = 15) + 
  geom_pointrange(aes(ymin = low, ymax = high)) + 
  xlab("Year") + 
  ylab(expression(phi)) + 
  scale_size_continuous(name = "Num Authors")

DF_decade <- DF$medium_first_gp %>% 
  mutate(who = "F") %>% 
  bind_rows(
    DF$medium_other_gp %>% 
      mutate(who = "O")
  ) %>% 
  mutate(Decade = ifelse(Year < 1990, "1980s", 
                         ifelse(Year < 2000, "1990s", 
                                ifelse(Year < 2010, "2000s", 
                                       ifelse(Year < 2020, "2010s", "2020s"))))) %>% 
  group_by(who, Decade) %>% 
  summarize_all(sum) %>% 
  pivot_longer(cols = -c(who, Decade, Year),
               names_to = "Country", 
               values_to = "Count")

# North America, Africa (combine), NWS Europe, Eastern Asia, Latin America, Rest of Europe, Rest of Asia, Everything Else 

DF_decade$Country_2 <- DF_decade$Country
DF_decade$Country_2 <- gsub(".*Africa.*", "Africa", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Northern Europe|Southern Europe|Western Europe", "NWS Europe", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("South-Eastern Europe|Eastern Europe", "ESE Europe", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Central Asia|South-Eastern Asia|Southern Asia|Western Asia", "Asia", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Melanesia|Mirconesia|New zealand and Australia|Polynesia", "Other", DF_decade$Country_2)

DF_decade$Country_2 <- factor(DF_decade$Country_2, 
                              levels = c("Africa", "Asia", "Eastern Asia", 
                                         "ESE Europe", 
                                         "Latin America and the Caribbean",
                                         "North America", 
                                         "NWS Europe", "Other"))

DF_decade_sm <- DF_decade %>% 
  group_by(Country_2, Decade, who) %>% 
  summarize(Count = sum(Count), .groups = "keep")

medium_author <- ggplot(DF_decade_sm, aes(who, Count, fill = Country_2)) + 
    geom_bar(position="fill", stat="identity", color = "black") + 
  theme_classic(base_size = 15) + 
  facet_grid(~Decade) + 
  xlab("Author Type") + 
  ylab("Percent of Authors") + 
  scale_fill_brewer(name = "Region", palette = "Spectral", drop = FALSE)
```

```{r large-effects, warning = FALSE}
DF$large_first_gp <- DF$large_first_gp %>% 
  filter(aff_un != "other") %>% 
  pivot_wider(id_cols = Year, 
              names_from = aff_un, 
              values_from = count,
              values_fill = 0)

DF$large_other_gp <- DF$large_other_gp %>% 
  filter(aff_un != "other") %>% 
  pivot_wider(id_cols = Year, 
              names_from = aff_un, 
              values_from = count,
              values_fill = 0) %>% 
  select(colnames(DF$large_first_gp))

large_effect <- data.frame(
  year = 1:length(unique(DF$large_first_gp$Year)),
  v = 1:length(unique(DF$large_first_gp$Year)),
  low = 1:length(unique(DF$large_first_gp$Year)),
  high = 1:length(unique(DF$large_first_gp$Year))
)
i <- 1
for (year in unique(DF$large_first_gp$Year)){
  temp_table <- DF$large_first_gp %>% filter(Year == year) %>% select(-Year) %>% 
    bind_rows(DF$large_other_gp %>% filter(Year == year) %>% select(-Year))
  
  col_total <- colSums(temp_table)
  temp_table <- temp_table %>% 
    select(names(col_total)[col_total > 0])
  temp <- suppressWarnings(chisq.test(as.matrix(temp_table)))
  tryCatch(mote_temp <- v.chi.sq(x2 = temp$statistic, n = sum(temp_table), 
                        r = nrow(temp_table), c = ncol(temp_table), 
                        a = .05), 
       warning = function(w) { 
         mote_temp <<- v.chi.sq(x2 = temp$statistic, n = sum(temp_table), 
                        r = nrow(temp_table), c = ncol(temp_table), 
                        a = .05)
         mote_temp$vlow <<- 0
  }
  )
  large_effect$year[i] <- year
  large_effect$v[i] <- mote_temp$v
  large_effect$low[i] <- mote_temp$vlow
  large_effect$high[i] <- mote_temp$vhigh
  large_effect$people[i] <- mote_temp$n
  i <- i + 1
}

large_effect$high[is.na(large_effect$high)] <- 0
large_effect <- 
  large_effect %>% 
  filter(v != Inf)

large_dot <- ggplot(large_effect, aes(year,v)) + 
  geom_point(aes(size = people)) + 
  theme_classic(base_size = 15) + 
  geom_pointrange(aes(ymin = low, ymax = high)) + 
  xlab("Year") + 
  ylab(expression(phi)) + 
  scale_size_continuous(name = "Num Authors")

DF_decade <- DF$large_first_gp %>% 
  mutate(who = "F") %>% 
  bind_rows(
    DF$large_other_gp %>% 
      mutate(who = "O")
  ) %>% 
  mutate(Decade = ifelse(Year < 1990, "1980s", 
                         ifelse(Year < 2000, "1990s", 
                                ifelse(Year < 2010, "2000s", 
                                       ifelse(Year < 2020, "2010s", "2020s"))))) %>% 
  group_by(who, Decade) %>% 
  summarize_all(sum) %>% 
  pivot_longer(cols = -c(who, Decade, Year),
               names_to = "Country", 
               values_to = "Count")

# North America, Africa (combine), NWS Europe, Eastern Asia, Latin America, Rest of Europe, Rest of Asia, Everything Else 

DF_decade$Country_2 <- DF_decade$Country
DF_decade$Country_2 <- gsub(".*Africa.*", "Africa", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Northern Europe|Southern Europe|Western Europe", "NWS Europe", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("South-Eastern Europe|Eastern Europe", "ESE Europe", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Central Asia|South-Eastern Asia|Southern Asia|Western Asia", "Asia", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Melanesia|Mirconesia|New zealand and Australia|Polynesia", "Other", DF_decade$Country_2)

DF_decade$Country_2 <- factor(DF_decade$Country_2, 
                              levels = c("Africa", "Asia", "Eastern Asia", 
                                         "ESE Europe", 
                                         "Latin America and the Caribbean",
                                         "North America", 
                                         "NWS Europe", "Other"))

DF_decade_sm <- DF_decade %>% 
  group_by(Country_2, Decade, who) %>% 
  summarize(Count = sum(Count), .groups = "keep")

large_author <- ggplot(DF_decade_sm, aes(who, Count, fill = Country_2)) + 
    geom_bar(position="fill", stat="identity", color = "black") + 
  theme_classic(base_size = 15) + 
  facet_grid(~Decade) + 
  xlab("Author Type") + 
  ylab("Percent of Authors") + 
  scale_fill_brewer(name = "Region", palette = "Spectral", drop = FALSE)
```

```{r fig-author-gpe, include = TRUE, fig.cap="A comparison of author affiliation geopolitical regions across decades. F stands for first authors and O stands for other authors.", fig.width=10, fig.height=6}
small_author + ggtitle("10-49 Authors") + #theme(legend.position = "none") +
medium_author + ggtitle("50-99 Authors") + #theme(legend.position = "none") + 
large_author + ggtitle("100 + Authors") + #theme(legend.position = "none") + 
guide_area() + 
plot_layout(
  ncol = 2,
  nrow = 2, 
  guides = "collect")

ggsave("figure/figure_7_author_gpe.png", width = 10, height = 6, units = "in")
```

```{r fig-effect-gpe, include = TRUE, fig.cap = "Effect size of the differences in representation for UN Regions for author affiliations in big-team science papers by year. Larger dots indicate more papers and authors represented in the calculation of effect size.", fig.width=10, fig.height=6}
all_effects <- bind_rows(
  small_effect %>% 
    mutate(type = "Small"),
  medium_effect %>% 
    mutate(type = "Medium"), 
  large_effect %>% 
    mutate(type = "Large") 
) %>% 
  mutate(type = factor(type, levels = c("Small", "Medium", "Large"),
                       labels = c("10-49 Authors", 
                                  "50-99 Authors", 
                                  "100+ Authors"))) %>% 
  mutate(Decade = ifelse(year < 1990, "1980s", 
                         ifelse(year < 2000, "1990s", 
                                ifelse(year < 2010, "2000s", 
                                       ifelse(year < 2020, "2010s", "2020s")))))

ggplot(all_effects %>% 
         arrange(v) %>% 
         mutate(count = 1:nrow(all_effects)) %>% 
         filter(year < 2024),
       aes(year, v)) + 
  facet_wrap(~type) + 
  geom_point(aes(size = people)) +
  geom_linerange(aes(ymin = low, ymax = high), alpha = .5) +
  theme_classic(base_size = 15) +
  theme(legend.position = "none") + 
  xlab("Year of Publication") + 
  ylab("Cramer's V")

ggsave("figure/figure_8_author_effect_gpe.png", width = 10, height = 6, units = "in")
```

Figure \@ref(fig:fig-author-gpe) indicates the percent of authors in
regions. In general, we found the same pattern as the overall analysis
wherein most authors are from Europe and North America. The pattern of
representation is roughly similar for the separation of small, medium,
and large numbers of authors on papers. Across time, the representation
does appear to diversify, with more representation in Asia, Latin
American, and Africa. Figure \@ref(fig:fig-effect-gpe) represents the
size of the differences in first/corresponding authors and other authors
across time and number of authors. The differences in representation are
larger for papers with more authors; however, the effects are non-zero
for many of the comparisons. Encouragingly, over time these effects
appear to diminish in size. One limitation with the calculation of
effect sizes for count data is the sensitivity of the data to sample
size (i.e., $\chi^2$ is upwardly biased by sample size, and $V$ is
calculated based on this value). While we used the inclusion of zero as
our boundary for "significance", the interpretation of the effects is
that most are likely small: $V$ \< .05:
`r apa_num(sum(all_effects$v <.05)/nrow(all_effects)*100)`%, $V$ \< .10:
`r apa_num(sum(all_effects$v < .10)/nrow(all_effects)*100)`%, $V$ \<
.20: `r apa_num(sum(all_effects$v < .20)/nrow(all_effects)*100)`%.

\newpage

# Discussion

In this investigation, we explored the publication rates, areas, and
researchers involved in BTS publications. Over a half-million articles
were published in nearly 15,000 journals since 1970 that qualified as
BTS articles. The areas of publication were aligned to cancer and
genetics research in medicine and oncology for Health and Life Sciences,
physics and chemistry for the Physical Sciences, and psychology for the
Social Sciences. All areas of research show growth in the number of
publications and authors included on manuscripts, replicating previous
investigations [@sinatra2015; @wuchty2007; @hunter2008].

Our investigation expands previous research by additionally focusing on
diversity in seniority of authors and geopolitical affiliation. The
number of earlier career scholars increased across years, indicating
that big teams may be accessible to different types of individuals, not
just older, established researchers. This result is especially
interesting given the publish-or-perish model still present in most
institutions, as it may seem that large-scale projects could be a risky
choice for non-permanent researchers. BTS projects are often slow to
publish, there is no guarantee for publication, and incentives are often
lower for non-corresponding authors. However, with a large team, the
distribution of work could imply less effort on individual non-leading
members, and research has shown that larger-team publications do receive
more citations and appear to have higher impact [@larivière2015].

In general, it appears that there is a decrease in the average number of
publications a researcher has when publishing in a BTS paper over time,
mirroring career length results. This result is likely attributable to
the number of early career scholars joining projects, but also may
support increased accessibility for individuals to be involved.
Globalization, the internet, and the focus on interdisciplinary research
are potentially driving forces behind our results, but, hopefully, the
results also point to a decline in scientific gatekeeping [@lu2007;
@siler2015].

The variability in the types of researchers involved in publications
also decreased across time in most areas of science with a decrease in
variability for career length. As mentioned, an increase in early career
researchers and numbers of publications could explain this effect
mathematically, potentially with other social influences mentioned
above. The variability in the number of publications is decreasing in
the Physical Sciences, mirroring the career length results, but the
opposite effect was found in the Health and Social Sciences. We see no
clear reason why career variability would decrease while the variability
in the number of publications would increase. The effect sizes for
career length were much larger than the effects for number of
publications. One speculation is the increasing requirements for a
competitive faculty role application. Given the limited number of
positions, one potential way to distinguish their application would be a
larger number of publications in their early career [@caplow2017;
@kyvik2003].

The number of geopolitical entities for researcher affiliation is
increasing over time, showing the results of globalization and the
ability to connect across time zones and cultures [@xie2014]. While our
definition of BTS required at least ten different institutional
affiliations, we did not filter papers by geopolitical region, and thus,
a manuscript could rely solely on institutions within a single country.
The Physical Sciences did not show an increase in diversity of regions
represented, however, it could be argued that the development of large
research centers like CERN forced earlier diversity than other sciences
(i.e., because CERN specifically recruited scientists from sponsoring
nations). The Life, Health, and Social Sciences saw an increase in the
number of regions represented with the highest increase in the Social
Sciences. This result likely corresponds with an increased interest in
big team science publications in psychology [@coles2022;
@forscher2022a], and the desire to diversify the populations represented
in psychological research [@henrich2010; @newson2021].

While publications overall are diversifying, we found differences in the
representation for first/corresponding authors versus all other authors.
In general, first authors appear to be less diverse, representing
European and North American authors, while other authors include more
Asian and African authors. These effect sizes were often small, but the
inequality persists across years. Diverse teams are more likely to have
papers with stronger “impact” [@freeman2015; @hinnant2012; @jones2008;
@yang2022] with higher citation metrics for more diverse author lists.
The introduction of contributorship models [e.g., CRediT, @allen2019]
will hopefully continue to push these effects down, as they highlight
each individual's contribution to a manuscript.

The limitations for this research are tied to the curation of the Scopus
dataset: the correct author affiliations, the correct author publication
information, and the correctly marked geopolitical entity. We had
planned to analyze educational levels change over time; however, this
data was mostly blank within the Scopus archive. Scopus is a carefully
curated and large dataset, but these limitations must be kept in mind
when interpreting the results. Publication language diversity was not
investigated, and a previous study indicates that most publications in
big databases are in English [@albarillo2014]. Certainly, publications
in non-English languages would improve the statistics on diversity in
scientific publishing - but the English language barrier likely exists
regardless of inclusion in databases [@meneghini2007;
@ramírez-castañeda2020].

Big teams can provide high-impact, important research within scientific
publishing, and this report suggests a promising trend of increasing
publications that include earlier career and more diverse scholars.
These partnerships introduce new challenges to collaboration from
interpersonal conflict, infrastructure, incentives, to international
political situations [@forscher2022a]. The implications for retention
and promotion processes across a broad span of regions should be
explored to improve diversity with the understanding of the differential
impact of incentives for participating in big team studies.

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}

::: {#refs custom-style="Bibliography"}
:::

\endgroup

\newpage

# (APPENDIX) Appendix {.unnumbered}

```{r child = "appendix.Rmd"}
```
