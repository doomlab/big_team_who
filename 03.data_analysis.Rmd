---
title: "Data Analysis"
author: "Erin M. Buchanan"
date: "Last Knitted: `r Sys.Date()`"
output: html_document
---

```{r setup_analysis, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

https://www.science.org/content/page/science-information-authors

## Libraries

```{r}
library(dplyr)
library(bib2df)
library(rio)
library(tidyr)
library(ggplot2)
library(nlme)
library(RColorBrewer)
library(countrycode)
library(maps)
library(MOTE)
current_year <- 2022
#### fix sau chins paper #### https://osf.io/gq92w/ 
```

## Import Bib Data

In this section, we are importing the bibtex file that includes all the papers we are going to use. 

Notes:

  - We used the preprint manuscript for some papers because they had the entire author list, we will update their references manually for the final dataset. 
  - We will have to manually add the names for several papers that used consortium authors. 
  - The pre-reg of this document only examines a few authors/papers to ensure code can be run and develop workflow. 

```{r}
bibs <- bib2df("papers.bib")

# get data into long format
long_bib <- bibs %>% unnest_longer(col = AUTHOR)

# remove this nonsense
long_bib$AUTHOR <- gsub("[{}]", "", long_bib$AUTHOR)

# now split the names into last, first middle 
# first split on the comma only 
long_bib <- long_bib %>% separate(col = AUTHOR, sep = ",", 
                                  into = c("last", "first"), 
                                  extra = "merge")

# remove the first space
long_bib$first <- gsub("^ ", "", long_bib$first)

# then split on space
long_bib <- long_bib %>% separate(col = first, sep = " ", 
                                  into = c("first", "middle"),
                                  extra = "merge")

# drop editor column so it is a non-nested DF
long_bib <- long_bib %>% select(-EDITOR)
```

In this section, we will add the information for authors when they used a consortium authorship. 

```{r}

```

## Import Author Data

```{r}
id_list <- import("test_utf8.xlsx")

o_works <- import("ORCID_works.csv")
o_ed <- import("ORCID_ed.csv")
o_job <- import("ORCID_job.csv")

s_works <- import("scholar_works.csv") 
s_info <- import("scholar_info.csv")
```

## Hand Coded Variables

```{r}
# will summarize types of research ----
table(o_works$type)
o_works$our_type <- o_works$type
o_works$our_type <- gsub("edited-book|book.+", "book", o_works$our_type)
o_works$our_type <- gsub("conference.+", "conference", o_works$our_type)
o_works$our_type <- gsub("dissertation-thesis|supervised-student.+", "thesis", o_works$our_type)
o_works$our_type <- gsub("magazine.+|report|dictionary-entry", "other-pub", o_works$our_type)
o_works$our_type <- gsub("working-paper", "preprint", o_works$our_type)
o_works$our_type <- gsub("website", "other", o_works$our_type)
table(o_works$our_type)

# will code job data ----
table(o_job$employment_summary_role_title)
o_job$our_job <- tolower(o_job$employment_summary_role_title)
o_job$our_job <- trimws(o_job$our_job)
o_job$our_job <- gsub("visit\\s*|visiting\\s*", "", o_job$our_job)
o_job$our_job <- gsub("ass\\. prof\\.|.*assistant professor.*", "assistant professor", o_job$our_job)
o_job$our_job <- gsub(".*associate professor.*", "associate professor", o_job$our_job)
o_job$our_job <- gsub(".*lecturer.*", "lecturer", o_job$our_job)
o_job$our_job <- gsub("assegnisti|.+post.+|juan de la cierva researcher|post-doc.*|postdoc.*", "post doc", o_job$our_job)
o_job$our_job <- gsub("borsisti|.*fellow.*", "fellow", o_job$our_job)
o_job$our_job <- gsub("academic|collaboratori|guest researcher|evaluation specialist|junior specialist|lab manager|personale esterno ed autonomi|research analyst|research associate|research scientist|researcher.*|scholar|senior statistician|special volunteer", "researcher", o_job$our_job)
o_job$our_job <- gsub(".*intern.*|research asistant", "research assistant", o_job$our_job)
o_job$our_job <- gsub("dottorandi|.*phd.*", "grad student", o_job$our_job)
o_job$our_job <- gsub(".*educator.*|teaching assistant", "lecturer", o_job$our_job)
o_job$our_job <- gsub(".*full.*professor.*", "professor", o_job$our_job)
o_job$our_job <- gsub(".*head.*", "head", o_job$our_job)
o_job$our_job <- gsub("centennial professor|prof\\.|professor of cognitive analytics|proffessor.*|^temporal proffesor.*", "professor", o_job$our_job)
table(o_job$our_job)

# hand code education ----
table(o_ed$education_summary_role_title)
o_ed$our_ed <- tolower(o_ed$education_summary_role_title)
o_ed$our_ed <- trimws(o_ed$our_ed)
o_ed$our_ed <- gsub("[[:punct:]]", "", o_ed$our_ed)
o_ed$our_ed <- gsub(".*phd.*|.*doctor.*|.*dr.*|^md|^jd", "doctor", o_ed$our_ed)
o_ed$our_ed <- gsub(".*bachelor.*|.*bsc.*|psicologia|physics enginnering|filosofia|free studies|electronics enginnering|free studies|^ba$|^bs$|^ba in.*|^bs .*|bsocsci.*|biology", "bachelor", o_ed$our_ed)
o_ed$our_ed <- gsub(".*master.*|.*msc.*|^ma$|masters.*|mse|mres.*|^magrersocoec", "masters", o_ed$our_ed)
o_ed$our_ed <- gsub("masters of business and economics", "masters", o_ed$our_ed)
o_ed$our_ed <- gsub("visiting researcher|venia docendi in business administration|graduate student", NA, o_ed$our_ed)
table(o_ed$our_ed)

# keywords of articles ----
bibs$our_keyword <- tolower(bibs$KEYWORDS)
bibs$our_keyword <- gsub(".*social.*|.*facial feedback hypothesis.*|.*attitude.*|.*interpersonal.*|.*viral infection.*|.*moral judgment.*|.*economics.*|.*relationships.*|.*morality.*|.*ultimatum.*|.*offense.*|psychology, human behaviour", "Social", bibs$our_keyword)
bibs$our_keyword <- gsub("intelligence|.*recognition memory.*|.*cognitive.*|.*working memory.*|.*evolution.*|.*priming.*|.*multivariate.*|.*magical thinking.*|.*legal psychology.*", "Cognitive", bibs$our_keyword)
bibs$our_keyword <- gsub(".*scientific community.*|.*life course.*|.*metascience.*", "Metascience", bibs$our_keyword)

bibs$title2 <- tolower(gsub("[[:punct:]]", "", bibs$TITLE))

bibs$our_keyword[grepl("message framing|egodepletion|facial feedback|turri|emotion|motivation|mortality salience|stereotype threat|moral judgments|trafimow|experimental philosophy", 
                       bibs$title2)] <- "Social"
bibs$our_keyword[grepl("semantic mismatch|priming|actionsentence|memory|eeg|object orientation|cognitive|natural language", 
                       bibs$title2)] <- "Cognitive"
bibs$our_keyword[grepl("toddlers|infancy research", 
                       bibs$title2)] <- "Developmental"
bibs$our_keyword[grepl("researchers choices|diffusion decision|many analysts|pool quality|variation in replicability|hidden universe|psychological science", 
                       bibs$title2)] <- "Metascience"
bibs$our_keyword[grepl("subjective wellbeing|mental illness|online alcohol survey", 
                       bibs$title2)] <- "Clinical"
bibs$our_keyword[grepl("immediate feedback",
                       bibs$title2)] <- "Educational"

table(bibs$title2[is.na(bibs$our_keyword)])
table(bibs$our_keyword, useNA = "ifany")
```

## Journal Information

```{r}
JIF <- import("jif.xlsx")
```

- make sure preprints we are using also have real journal merged in 

```{r}
journal_count <- bibs %>% group_by(JOURNAL) %>% 
  summarize(freq = n()) %>% 
  arrange(desc(freq))

journal_count$JOURNAL[is.na(journal_count$JOURNAL)] <- "Pre-Print"
```

## Article Information 

```{r}
article_overall <- as.data.frame(table(bibs$our_keyword)) %>% 
  arrange(desc(Freq)) %>% 
  mutate(Percent = Freq / sum(Freq) * 100)
article_time <- as.data.frame(table(bibs$our_keyword, bibs$YEAR))

article_time_plot <- ggplot(article_time, aes(Var2, Freq, fill = Var1)) +
  geom_bar(position="stack", stat="identity") + 
  theme_classic() + 
  xlab("Publication Year") + 
  ylab("Number of Papers") + 
  scale_fill_brewer(palette = "RdBu", name = "Research Area")

```

## Person Analysis 

### Create Summary Statistics 

```{r}
# will filter out bad data, here's an example
summary(o_works$publication_date_year_value)
o_works$publication_date_year_value[o_works$publication_date_year_value < 1920] <- NA

# create summary variables 

# total pubs and career since first pub
o_works_summary <- o_works %>% 
  group_by(ORCID) %>% 
  summarize(o_career_1_pub = min(publication_date_year_value, na.rm = T),
            o_total_pub = n())

s_works_summary <- s_works %>% 
  group_by(scholar) %>% 
  summarize(s_career_1_pub = min(year, na.rm = T),
            s_total_pub = n())

# career since first degree
o_ed_summary <- o_ed %>% 
  group_by(ORCID) %>% 
  summarize(o_career_1_degree = min(education_summary_end_date_year_value, na.rm = T)) 
# remember to ignore inf 
o_ed_summary$o_career_1_degree[o_ed_summary$o_career_1_degree < 0] <- NA
o_ed_summary$o_career_1_degree[o_ed_summary$o_career_1_degree == Inf] <- NA

# create a table that's ORCID, job, education, year for each year within bib 2013 to 2022
roles_years <- data.frame(
  ORCID = rep(unique(o_ed$ORCID), each = (2022 - 2012)),
  year = rep(2013:2022, length(unique(o_ed$ORCID))),
  education = rep(NA, length(rep(unique(o_ed$ORCID), each = (2022 - 2012)))),
  job = rep(NA, length(rep(unique(o_ed$ORCID), each = (2022 - 2012))))
)

# for jobs fill in "current" or end date
# Find users with blanks
employ_fix <- o_job %>% 
  filter(is.na(employment_summary_end_date_year_value)) %>% 
  select(ORCID, employment_summary_start_date_year_value, employment_summary_role_title) %>% 
  filter(!is.na(employment_summary_role_title)) %>% 
  pull(ORCID)

for (i in 1:length(employ_fix)){
  # For each one find the number of rows 
  temp_fix <- o_job %>% 
  #filter(is.na(employment_summary_end_date_year_value)) %>% 
  select(ORCID, employment_summary_start_date_year_value,
         employment_summary_end_date_year_value,
         employment_summary_role_title) %>% 
    filter(ORCID == employ_fix[i]) %>% 
    filter(!is.na(employment_summary_role_title))
  
  # if only one row, make it now
  if (nrow(temp_fix) == 1){
    o_job$employment_summary_end_date_year_value[
      o_job$ORCID == employ_fix[i] &
      !is.na(o_job$employment_summary_role_title)
      ] <- current_year
  }
  
  if (nrow(temp_fix) > 1){
    
    lead_values <- c(current_year,
                     o_job$employment_summary_start_date_year_value[
      o_job$ORCID == employ_fix[i] &
      !is.na(o_job$employment_summary_role_title)
    ])
    lead_values <- lead_values[-length(lead_values)]
    
    # Use the lead or other end function 
    for (q in 1:length(lead_values)){
      
      if (is.na(o_job$employment_summary_end_date_year_value[
        o_job$ORCID == employ_fix[i] &
        !is.na(o_job$employment_summary_role_title)
      ][q])) {
        
      o_job$employment_summary_end_date_year_value[
        o_job$ORCID == employ_fix[i] &
        !is.na(o_job$employment_summary_role_title)
      ][q] <- lead_values[q]
        
      } # close lead if only na
      
    } # close lead values loop
    
  } # close if more than one row
  
} # close for all users

# check when values don't make sense
o_job %>% 
  filter(employment_summary_end_date_year_value < employment_summary_start_date_year_value)

# make employment by year 
o_ed_explode <- data.frame()
o_job_explode <- data.frame()

for (year in 2013:2022){
 
  temp <- o_ed %>% 
    filter(education_summary_end_date_year_value <= year) %>% 
    arrange(desc(education_summary_end_date_year_value)) %>% 
    filter(!duplicated(ORCID)) %>% 
    select(ORCID, education_summary_role_title, our_ed,
           education_summary_organization_address_country) %>% 
    mutate(year_merge = year)
  
  o_ed_explode <- bind_rows(o_ed_explode, temp)
  
  temp2 <- o_job %>% 
    filter(employment_summary_end_date_year_value >= year) %>% 
    arrange(desc(employment_summary_end_date_year_value)) %>% 
    filter(!duplicated(ORCID)) %>% 
    select(ORCID, employment_summary_role_title, our_job,
           employment_summary_organization_address_country) %>% 
    mutate(year_merge = year)
   
  o_job_explode <- bind_rows(o_job_explode, temp2) 

}

 roles_years <- roles_years %>% 
   left_join(o_ed_explode, 
             by = c("ORCID" = "ORCID", "year" = "year_merge")) %>% 
   left_join(o_job_explode, 
             by = c("ORCID" = "ORCID", "year" = "year_merge"))
```

### Merge Information Back 

```{r}
merged_df <- long_bib %>% 
  left_join(
    # note this isn't perfect ... will have to make sure all versions 
    # get matched 
    (id_list %>% select(first, last, ORCID, scholar)), 
    by = c("first" = "first", "last" = "last") 
  ) %>% 
  left_join(
    o_works_summary, 
    by = c("ORCID" = "ORCID")
  ) %>% 
  left_join(
    s_works_summary,
    by = c("scholar" = "scholar")
  ) %>% 
  left_join(
    o_ed_summary,
    by = c("ORCID" = "ORCID")
  ) %>% 
  left_join(
    (s_info %>% select(scholar, h_index, i10_index)),
    by = c("scholar" = "scholar")
  ) %>% 
  left_join(
    roles_years,
    by = c("ORCID" = "ORCID", "YEAR" = "year")
  )

```

```{r}
# total count of authors
author_count <- 
  merged_df %>% 
  group_by(TITLE) %>% 
  summarize(author_count = n(),
            year = mean(YEAR))
```

### Graph Year Fix

```{r}
merged_df$graph_year <- factor(merged_df$YEAR)
```

### Career Length

```{r}
# since first pub ORCID ----
merged_df$TITLE_color <- as.numeric(factor(merged_df$TITLE))

# graph
o_career_graph <- ggplot(merged_df, aes(graph_year, o_career_1_pub)) + 
  geom_violin() + 
  geom_jitter(height = 0, width = 0.2, aes(color = TITLE_color)) + 
  theme_classic() + 
  ylab("Career Length (ORCID First Pub)") + 
  xlab("Year of Publication") +
  theme(legend.position="none") 

# year model slope 
o_career_model <- lme(o_career_1_pub ~ YEAR,
                      data = merged_df,
                      na.action = "na.omit",
                      random = ~1|ORCID)

# variance model 
variance_df <- merged_df %>% 
  group_by(TITLE) %>% 
  summarize(year = mean(YEAR), 
            var_o_career_1_pub = sd(o_career_1_pub, na.rm = T),
            var_s_career_1_pub = sd(s_career_1_pub, na.rm = T), 
            var_o_career_1_degree = sd(o_career_1_degree, na.rm = T),
            var_o_total = sd(o_total_pub, na.rm = T), 
            var_s_total = sd(s_total_pub, na.rm = T))

var_o_career_model <- lm(var_o_career_1_pub ~ year, 
                          data = variance_df,
                          na.action = "na.omit")
```

```{r}
# since first pub scholar ----

# graph 
s_career_graph <- ggplot(merged_df, aes(graph_year, s_career_1_pub)) + 
  geom_violin() + 
  geom_jitter(height = 0, width = 0.2, aes(color = TITLE_color)) + 
  theme_classic() + 
  ylab("Career Length (Scholar First Pub)") + 
  xlab("Year of Publication") +
  theme(legend.position="none")  

# year model slope 
s_career_model <- lme(s_career_1_pub ~ YEAR,
                      data = merged_df,
                      na.action = "na.omit",
                      random = ~1|scholar)

# variance  model 
var_s_career_model <- lm(var_s_career_1_pub ~ year, 
                          data = variance_df,
                          na.action = "na.omit")
```

```{r}
# since first degree ORCID ----
o_career_graph_ed <- ggplot(merged_df, aes(graph_year, o_career_1_degree)) +
  geom_violin() + 
  geom_jitter(height = 0, width = 0.2, aes(color = TITLE_color)) + 
  theme_classic() + 
  ylab("Career Length (ORCID First Degree)") + 
  xlab("Year of Publication")  +
  theme(legend.position="none")  

# year model slope
o_career_ed_model <- lme(o_career_1_degree ~ YEAR,
                      data = merged_df,
                      na.action = "na.omit",
                      random = ~1|ORCID)

# variance model 
var_o_career_ed_model <- lm(var_o_career_1_degree ~ year, 
                          data = variance_df,
                          na.action = "na.omit")
```

### Employment Levels

```{r}
merged_df$our_job <- factor(merged_df$our_job, 
                            levels = c("research assistant", 
                                       "post doc", 
                                       "researcher", 
                                       "lecturer", 
                                       "fellow",
                                       "assistant professor",
                                       "associate professor", 
                                       "professor", "head"),
                            labels = tools::toTitleCase(c("research assistant", 
                                       "post doc", 
                                       "researcher", 
                                       "lecturer", 
                                       "fellow",
                                       "assistant professor",
                                       "associate professor", 
                                       "professor", "head")))

employment_overall <- as.data.frame(table(merged_df$our_job)) %>% 
  arrange(desc(Freq)) %>% 
  mutate(Percent = Freq / sum(Freq) * 100)
employment_time <- as.data.frame(table(merged_df$our_job, merged_df$graph_year))

employment_time_plot <- ggplot(employment_time, aes(Var2, Freq, fill = Var1)) +
  geom_bar(position="stack", stat="identity") + 
  theme_classic() + 
  xlab("Publication Year") + 
  ylab("Number of Researchers") + 
  scale_fill_brewer(palette = "RdBu", name = "Employment Category")
```

### Education Levels

```{r}
merged_df$our_ed <- factor(merged_df$our_ed, 
                            levels = c("bachelor", 
                                       "masters", 
                                       "doctor"),
                            labels = tools::toTitleCase(c("bachelor", 
                                       "masters", 
                                       "doctor")))

education_overall <- as.data.frame(table(merged_df$our_ed)) %>% 
  arrange(desc(Freq)) %>% 
  mutate(Percent = Freq / sum(Freq) * 100)
education_time <- as.data.frame(table(merged_df$our_ed, merged_df$graph_year))

edu_colors <- brewer.pal(6, "RdBu")[c(1,3,6)]

education_time_plot <- ggplot(education_time, aes(Var2, Freq, fill = Var1)) +
  geom_bar(position="stack", stat="identity") + 
  theme_classic() + 
  xlab("Publication Year") + 
  ylab("Number of Researchers") + 
  scale_fill_manual(values = edu_colors, 
                    name = "Education Category")
```

### Types of Publications

```{r}
publication_overall <- as.data.frame(table(o_works$our_type)) %>% 
  arrange(desc(Freq)) %>% 
  mutate(Percent = Freq / sum(Freq) * 100)
```

### Publication Metrics

```{r}
# total pubs orcid ----

# graph 
o_total_graph <- ggplot(merged_df, aes(graph_year, o_total_pub)) + 
  geom_violin() + 
  geom_jitter(height = 0, width = 0.2, aes(color = TITLE_color)) + 
  theme_classic() + 
  ylab("Total Number of Publications (ORCID)") + 
  xlab("Year of Publication") +
  theme(legend.position="none")  

# year model slope 
o_total_model <- lme(o_total_pub ~ YEAR,
                      data = merged_df,
                      na.action = "na.omit",
                      random = ~1|scholar)

# variance  model 
var_o_total_model <- lm(var_o_total ~ year, 
                          data = variance_df,
                          na.action = "na.omit")
```

```{r}
# total pubs scholar ----

# graph 
s_total_graph <- ggplot(merged_df, aes(graph_year, s_total_pub)) + 
  geom_violin() + 
  geom_jitter(height = 0, width = 0.2, aes(color = TITLE_color)) + 
  theme_classic() + 
  ylab("Total Number of Publications (ORCID)") + 
  xlab("Year of Publication") +
  theme(legend.position="none")  

# year model slope 
s_total_model <- lme(s_total_pub ~ YEAR,
                      data = merged_df,
                      na.action = "na.omit",
                      random = ~1|scholar)

# variance  model 
var_s_total_model <- lm(var_s_total ~ year, 
                          data = variance_df,
                          na.action = "na.omit")
```

### Geopolitical Regions  

```{r}
# create a world map 
world_map <- map_data(map = "world")
world_map$region <- iso.alpha(world_map$region)
world_map <- subset(world_map, region != "AQ")

# map of degree representation ----
o_ed_summary_map <- o_ed %>% 
  group_by(ORCID) %>% 
  arrange(desc(education_summary_start_date_year_value)) %>% 
  ungroup() %>% 
  filter(!duplicated(ORCID)) %>% 
  select(ORCID, education_summary_organization_address_country) 

# summarize the same samples
o_ed_country <- o_ed_summary_map %>% 
      group_by(education_summary_organization_address_country) %>% 
      summarize(n = n()) %>% 
      filter(!is.na(education_summary_organization_address_country))

# make a map on a continuous scale
o_ed_country_graph <- 
  ggplot(o_ed_country) +
  geom_map(aes(map_id = education_summary_organization_address_country, fill = n), map = world_map) +
  geom_polygon(data = world_map, 
               aes(x = long, y = lat, group = group), 
               colour = 'black', fill = NA) + 
  theme_void() + 
  scale_fill_distiller(name = "Sample Size",
                       palette = "Greys",
                       direction = 1,
                       na.value = "white") 

# map of last job representation ----
o_job_summary <- o_job %>% 
  group_by(ORCID) %>% 
  arrange(desc(employment_summary_start_date_year_value)) %>% 
  ungroup() %>% 
  filter(!duplicated(ORCID)) %>% 
  select(ORCID, employment_summary_organization_address_country) 

# summarize the same samples
o_job_country <- o_job_summary %>% 
      group_by(employment_summary_organization_address_country) %>% 
      summarize(n = n()) %>% 
      filter(!is.na(employment_summary_organization_address_country))

# make a map on a continuous scale
o_job_country_graph <- 
  ggplot(o_job_country) +
  geom_map(aes(map_id = employment_summary_organization_address_country, fill = n), map = world_map) +
  geom_polygon(data = world_map, 
               aes(x = long, y = lat, group = group), 
               colour = 'black', fill = NA) + 
  theme_void() + 
  scale_fill_distiller(name = "Sample Size",
                       palette = "Greys",
                       direction = 1,
                       na.value = "white")

# how many different countries does each year have and is that getting bigger -----
country_summary <- merged_df %>% 
  group_by(TITLE) %>% 
  summarize(year = mean(YEAR), 
            edu_country = length(table(education_summary_organization_address_country)),
            job_country = length(table(employment_summary_organization_address_country)))

# totals by edu
edu_country_model <- lm(edu_country ~ year, 
                          data = country_summary,
                          na.action = "na.omit")

# totals by job
job_country_model <- lm(job_country ~ year, 
                          data = country_summary,
                          na.action = "na.omit")

```

### CRediT and WEIRD

```{r}
# transform to un regions
merged_df$un_region_ed <- 
  countrycode(
    sourcevar = merged_df$education_summary_organization_address_country,
    origin = "iso2c",
    destination = "un.regionsub.name")

merged_df$un_region_job <- 
  countrycode(
    sourcevar = merged_df$employment_summary_organization_address_country,
    origin = "iso2c",
    destination = "un.regionsub.name")

# for each paper 
first_probs_ed <- list()
first_probs_job <- list()
last_probs_ed <- list()
last_probs_job <- list()

# titles
titles <- author_count$TITLE[author_count$author_count >= 10]
years <- author_count$year[author_count$author_count >= 10]

for (i in 1:length(titles)){
  
  # number of authors
  temp_count <- author_count$author_count[author_count$TITLE == titles[i]]
  # just this paper
  temp_DF <- merged_df %>% filter(TITLE == titles[i])
  # skip short
  if (temp_count < 10){ next }
  # number of size
  if (temp_count >=10 & temp_count < 50){ number_grab <- 3 }
  if (temp_count >=50 & temp_count < 100){ number_grab <- 5 }
  if (temp_count >= 100){ number_grab <- 10 }
  
  # first authors 
  first_probs_ed[[i]] <- as.data.frame(table(temp_DF$un_region_ed[c(1:number_grab, temp_count)], useNA = "ifany"))
  first_probs_job[[i]] <- as.data.frame(table(temp_DF$un_region_job[c(1:number_grab, temp_count)], useNA = "ifany"))
  
  # all other authors
  running_ed <- list()
  running_job <- list()
  
  #for (q in 1:temp_count){ # officially do this 
  for (q in 1:10){ #unofficially test with this 
    running_ed[[q]] <- temp_DF[-c(1:number_grab, temp_count), ] %>% 
      sample_n(number_grab+1) %>% 
      pull(un_region_ed) %>% 
      table(., useNA = "ifany") %>% 
      as.data.frame()
    
    running_job[[q]] <- temp_DF[-c(1:number_grab, temp_count), ] %>% 
      sample_n(number_grab+1) %>% 
      pull(un_region_job) %>% 
      table(., useNA = "ifany") %>% 
      as.data.frame()
    
  }
  
  ed_DF <- suppressMessages(bind_rows(running_ed))
  job_DF <- suppressMessages(bind_rows(running_job))
  colnames(ed_DF) <- colnames(job_DF) <- c("Var1", "Freq")
  
  last_probs_ed[[i]] <- ed_DF %>% group_by(Var1) %>% summarize(Freq = round(mean(Freq)))
  last_probs_job[[i]] <- job_DF %>% group_by(Var1) %>% summarize(Freq = round(mean(Freq)))
  
}

gpr_effects_ed <- bind_rows(first_probs_ed, .id = "source") %>% 
  full_join(
    bind_rows(last_probs_ed, .id = "source"), 
    by = c("source" = "source", "Var1" = "Var1")
  ) %>% 
  full_join(
    data.frame(TITLE = titles, year = years, 
               source = as.character(1:length(titles))),
    by = c("source" = "source")
  )
colnames(gpr_effects_ed) <- c("source", "unregion", "freq_first", 
                              "freq_last", "TITLE", "year")

gpr_effects_job <- bind_rows(first_probs_job, .id = "source") %>% 
  full_join(
    bind_rows(last_probs_job, .id = "source"), 
    by = c("source" = "source", "Var1" = "Var1")
  ) %>% 
  full_join(
    data.frame(TITLE = titles, year = years, 
               source = as.character(1:length(titles))),
    by = c("source" = "source")
  )
colnames(gpr_effects_job) <- c("source", "unregion", "freq_first", 
                               "freq_last","TITLE", "year")

# flatten down by year breakdown 
gpr_effects_ed$group <- NA
gpr_effects_ed$year <- as.numeric(gpr_effects_ed$year)
gpr_effects_ed$group[gpr_effects_ed$year < 2020] <- "Pre-2020"
gpr_effects_ed$group[gpr_effects_ed$year == 2020] <- "2020"
gpr_effects_ed$group[gpr_effects_ed$year > 2020] <- "Post-2020"

gpr_effects_ed_summary <- gpr_effects_ed %>% 
  select(group, unregion, freq_first, freq_last) %>% 
  group_by(group, unregion) %>% 
  summarize(total_first = sum(freq_first, na.rm = T),
            total_last = sum(freq_last, na.rm = T)) %>% 
  filter(!is.na(unregion))

gpr_effects_job$group <- NA
gpr_effects_job$year <- as.numeric(gpr_effects_job$year)
gpr_effects_job$group[gpr_effects_job$year < 2020] <- "Pre-2020"
gpr_effects_job$group[gpr_effects_job$year == 2020] <- "2020"
gpr_effects_job$group[gpr_effects_job$year > 2020] <- "Post-2020"

gpr_effects_job_summary <- gpr_effects_job %>% 
  select(group, unregion, freq_first, freq_last) %>% 
  group_by(group, unregion) %>% 
  summarize(total_first = sum(freq_first, na.rm = T),
            total_last = sum(freq_last, na.rm = T)) %>% 
  filter(!is.na(unregion))

# pre 2020 ----
x_pre2020 <- chisq.test(gpr_effects_ed_summary[gpr_effects_ed_summary$group == "Pre-2020", c("total_first", "total_last")])
v_pre2020 <- v.chi.sq(x2 = x_pre2020$statistic, 
                      n = sum(x_pre2020$observed),
                      r = nrow(x_pre2020$observed),
                      c = ncol(x_pre2020$observed))

# 2020 ----
x_2020 <- chisq.test(gpr_effects_ed_summary[gpr_effects_ed_summary$group == "2020", c("total_first", "total_last")])
v_2020 <- v.chi.sq(x2 = x_2020$statistic, 
                      n = sum(x_2020$observed),
                      r = nrow(x_2020$observed),
                      c = ncol(x_2020$observed))


# post 2020 ----
x_post2020 <- chisq.test(gpr_effects_ed_summary[gpr_effects_ed_summary$group == "Post-2020", c("total_first", "total_last")])
v_post2020 <- v.chi.sq(x2 = x_post2020$statistic, 
                      n = sum(x_post2020$observed),
                      r = nrow(x_post2020$observed),
                      c = ncol(x_post2020$observed))
```


