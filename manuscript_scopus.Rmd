---
title             : "Who does big team science?"
shorttitle        : "Big Team Science"
author: 
  - name          : "Erin M. Buchanan"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "326 Market St., Harrisburg, PA 17101"
    email         : "ebuchanan@harrisburgu.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Data curation
      - Formal Analysis
      - Methodology
      - Project administration
      - Visualization
      - Writing – original draft
      - Writing – review & editing
  - name          : "Savannah C. Lewis"
    affiliation   : "2"
    role:
      - Conceptualization
      - Data curation
      - Methodology
      - Project administration
      - Writing – original draft
      - Writing – review & editing
affiliation:
  - id            : "1"
    institution   : "Harrisburg University of Science and Technology"
  - id            : "2"
    institution   : "University of Alabama"
authornote: |
  Erin M. Buchanan is a Professor of Cognitive Analytics at Harrisburg University of Science and Technology. Savannah C. Lewis is a graduate student at the University of Alabama.  
  
  Thank you to Dwayne Lieck for providing an extensive list of large scale projects for this manuscript. 
abstract: |
  This paper examined the nature of publications in Big Team Science (BTS): large-scale collaborations between multiple researchers at multiple institutions. These projects can improve research by initiating collaborations that span across the globe, age groups, education levels, and subfields of research. As the number of BTS publications increase, it is useful to explore who is currently involved in BTS projects to determine diversity in both research subject and researcher representation. We examined the diversity of BTS publications and authors across more than half a million articles to investigate where and what is currently published, and author characteristics including differences in career length, publication metrics, affiliation, and affiliation geopolitical regions. Interestingly, BTS publications are increasingly dominated by early career researchers from WEIRD geopolitical regions with Health and Physical Science accounting for the majority of BTS articles. However, the increase in preprints, BTS articles, and non-WEIRD authors across time demonstrate the efforts of the science community to diversify its researchers. 
  
keywords          : "big team, science, authorship, credit"
floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
classoption       : "man"
editor_options: 
  markdown: 
    wrap: 72
  chunk_output_type: inline
bibliography: references.bib
# header-includes:
csl               : "includes/nature.csl"
# documentclass     : "apa7"
output            : papaja::apa6_pdf
appendix          :
  - "appendix.Rmd"
---

```{r setup, include = FALSE}
knitr::opts_knit$set(echo = FALSE, warning = FALSE, message = FALSE, include = FALSE, error = FALSE)
library(papaja)
library(knitr)
library(ggplot2)
library(treemapify)
library(countrycode)
library(rio)
library(maps)
library(dplyr)
library(tidyr)
library(MOTE)
library(MBESS)
library(patchwork)
library(ggplot2)
library(ggwordcloud)
library(figpatch)
library(RColorBrewer)
library(latex2exp)

strip_labels <- expression(
  "M Coefficient " = b[M],
  "SD Coefficient" = b[SD],
  "Effect Size" = R^2,
  "Coefficient" = b
)

label_expressions <- function(values) {
  stopifnot(is.expression(values))
  as_labeller(function(x) {
    if (is.null(names(values))) {
      x <- seq_along(x)
      if (length(x)!=length(values)) warning(paste0("Number of labels(", 
        length(values), ") does not match number of values (", length(x), ")"))
    }
    as.list(values[x])
  }, default = identity)
}

# things to import
var_list <- c("author_time", "career_time", "geo_country", "inst_time", 
              "keywords", "large_first_gp", "large_other_gp", "medium_first_gp", 
              "medium_other_gp", "normal_pub_type", "pub_time_count", 
              "pub_time_subject", "pub_types", "small_first_gp", "small_other_gp",
              "snip", "ASJC_codes", "snip_all")

var_list_import <- paste0("data/scopus_outputs/", var_list, ".xlsx")

DF <- lapply(var_list_import, import)
names(DF) <- var_list
```

According to the Oxford English dictionary, collaboration is two or more
people working together to achieve a certain goal [@oed2016].
Collaboration in scientific endeavors involves multiple researchers at
(potentially) multiple institutions to communicate and work together to
advance knowledge in their chosen field. Collaboration can manifest
uniquely in each project dependent on the skill sets, hypotheses, and
perspectives of collaborators. While collaboration is not new in
science, the current interest of "big team science" is increasing
[@coles2022; @forscher2022a; @stewart2017]. Big team science projects
and/or organizations utilize and run on large-scale collaboration to
ensure that diverse populations and ideas are brought into research
projects, which in turn allows for more reliability and generalizability
in the results and method of the study.

BTS appears to be expanding as a result of two sources: 1) increasing
globalization and technology that allows for real-time interdisciplinary
research, and 2) expanding interest in reproducibility, replication, and
generalizability [@maxwell2015; @nelson2018; @zwaan2018]. Technological
advances have provided easier ways to collaborate with people who are
from other universities and countries through document sharing platforms
(e.g., Google, GitHub, and the Open Science Framework), video chatting
platforms (e.g., Zoom, Microsoft Teams), and messaging and project
management platforms (e.g., Slack, Trello, when2meet, etc.). The
credibility movement seems to suggest that by having both collaborations
that span across the globe and subfields of research areas, age groups,
and education levels should help to drive science in the path of better
materials, reliability, generalizability and more robust sample sizes
(when necessary) in a study [@auspurg2021; @nosek2014method;
@lebel2018].

The credibility movement was originally defined by a focus on large
scale replications used in collaborative environments [@vazire2022].
Generally, the movement appears to have been driven by early career
researchers (i.e., those who are within five years of their first
appointment) [@maizey2019]; however, there are no large meta-scientific
investigations on this specific topic to date. Potentially, the lack of
investigation is tied to the newness of the large-scale research in many
fields, as it is only in recent years that publications like the Open
Science Collaboration [@opensciencecollaboration2015], Many Labs
Collaborations [@buttrick2020; @ebersole2016; @ebersole2020; @klein2018;
@klein2022; @mathur2020; @skorb2020] or the first papers from the
Psychological Science Accelerator [@bago2022; @buchanan2023;
@dorison2022; @jones2021;
@psychologicalscienceacceleratorself-determinationtheorycollaboration2022;
@moshontz2018; @wang2021]. Generally, the researcher incentive for
replication was low for three reasons. First, journals often prioritize
"novel" or new results which led to rejection of replication manuscripts
and publication bias [@franco2014; @hubbard1997; @nosek2012]. Second,
the "failure" to replicate was often placed on the replication team as
"bad science" rather than a careful consideration of publication biases
and (potential) questionable research practices [@klein2022;
@maxwell2015]. Last, why should someone want to spend time and resources
on an answer we already "know" [@isager2021; @isager2021a]?

However, the success and interest in the large-scale reproducibility
projects [@opensciencecollaboration2015; @10.7554/eLife.71601], paired
with the meta-scientific publications focusing on researcher practices
and incentive structures [@silberzahn2018many; @john2012] led to a
change in journal guidelines and incentives for researchers interested
in participating in large-scale replication studies [@grahe2014;
@kidwell2016; @nosek2015; @mayo-wilson2021]. For example, the support
for Registered Reports, papers accepted before the data has been
collected [@nosek2014; @stewart2020], and entire sub-sections of
journals devoted to only replication studies (e.g., *Nature, Royal
Society Open Science, Advances in Methods and Practices in Psychological
Science*) has allowed researchers to invest in projects that they know
should be published when the project is complete. Further, the
implementation of the Transparency and Openness Guidelines [@nosek2015]
and the Contributor Role Taxonomy (CRediT) system [@allen2019] have
pushed journals and researchers to promote more open, inclusive
publication practices.

The credibility movement has been mirrored by the calls for
diversification or de-WEIRDing (e.g., Western, Educated, Industrialized,
Rich, and Democratic) scientific research [@henrich2010; @newson2021;
@rad2018] by improving representation in research samples. Like the
large-scale studies in Physics [@aphilos2021; @castelnovo2018] and
Biology [@collins2003], the Social Sciences struggle to represent the
breadth of humanity across both researcher and population
characteristics. Now, grassroots organizations, such as the
Psychological Science Accelerator [@moshontz2018], ManyBabies
(<https://manybabies.github.io/>), NutNet (<https://nutnet.org/>), and
DRAGNet (<https://dragnetglobal.weebly.com/>) can begin to tackle these
issues by recruiting research labs from all over the globe to provide
diversity in geographic, linguistic, and researcher representation.
Publications have examined the global understanding of morality, face
processing, COVID-19 information signaling, and more [@bago2022;
@dorison2022; @jones2021;
@psychologicalscienceacceleratorself-determinationtheorycollaboration2022;
@vanbavel2022; @wang2021]. While these organizations and one-time groups
for BTS studies have provided an incredible wealth of data for the
scientific community, we do not yet know exactly *who* is involved with,
and benefits from, the BTS and credibility movement. Publications on BTS
generally explore challenges, lessons learned, and the need for BTS
[@forscher2022a; @coles2022].

Therefore, the goal of this manuscript is to examine the *people*
involved in BTS projects. We specifically examined the themes of
inclusivity, research careers, and research globalization. We see an
increasing interest and number of publications in BTS but we do not yet
know if this uptick in large-scale projects has diversified the *people*
involved in BTS. While a few publications have noted that BTS appears to
be early career researchers [@maizey2019], no one has systematically
investigated this perception. Further, it is unclear if the focus of
de-WEIRDing science has only focused on the representation of the
research participants or if it has also improved the representation of
researchers outside of North America and Europe. Last, who runs these
BTS projects? Do we see an increase in diversity for the authors who
generally receive the most credit for these projects (i.e., first
several author(s) and last author)? As hiring and promoting practices
often place a heavy weight on publications and especially "influential"
publications, it becomes necessary to critically examine the
representation present in authorship in BTS projects.

# Research Questions

-   Research Question 1: What publication sources publish big team
    science papers?
-   Research Question 2: What are the types of articles that are being
    published in big team science?
-   Research Question 3: Who is involved in big team science?

This manuscript was preregistered with the same conceptual ideas using
Google Scholar and ORC-ID databases (<https://osf.io/f2dtr>) but then
was updated with access to the Scopus database for a broader picture of
BTS projects (<https://osf.io/fheun>). All materials and code can be
found on our OSF page: <https://osf.io/cgx6u/> or corresponding GitHub
archive: <https://github.com/doomlab/big_team_who>.

# Method

## Publications

We have defined BTS publications as publications with at least ten
authors at ten different institutions that were published in
peer-reviewed journals or had posted a full paper pre-print. We used
data from 1970 and forward in the Scopus database, as it is noted online
that this time period includes cited references for calculation of
several of our variables described below. We will analyze our results
based on four subject areas present in the Scopus database: Physical
Sciences, Health Sciences, Social Sciences, and Life Sciences. We
filtered the database to include articles, articles in press, business
articles, conference papers, data papers, preprints, and surveys using
Elsevier's classification system. This project was supported by access
to the Scopus database through the International Center for the Study of
Research.

## Data Curation

### RQ1: Publisher Information

We extracted the following information for publication sources: the name
of the publication (source title), subject area (both the large four
subject areas and the smaller four digit all science journal
classification [ASJC] code), and the journal impact using the Source
Normalized Impact per Paper (SNIP).

### RQ2: Publication Information

For each publication of the identified BTS publications, we examined the
full four digit ASJC subject areas codes for each of the larger four
subject areas and the keywords present for these publications.

### RQ3: Author Information

The author list was extracted from each publication. Next, we used the
author and affiliation arrays to curate a list of all publications and
author information included in BTS papers to calculate the variables
described below.

***Career Length***. Career length for each author was defined as the
year of the first publication minus the current year listed for each
author.

***Institution and Geopolitical Region***. We used the affiliation ids
and country to gather information about the places of education and/or
employment for authors. Geopolitical region was created by binning these
codes into United Nation Regions.

***Education***. We collected degree information from the author table.
Information on this variable is in the appendix.

***Types of Publications***. We took information from the publication
type variable for each author's publications to present information
about the types of papers BTS authors publish. Information on this
variable is in the appendix.

***Publication Metrics***. For each author, we calculated the total
number of publications, and the h-index. The h-index represents the
highest *h* number of publications that have at least *h* citations.
*h*-count was only used for descriptive statistics.

# Results

We used the 95% confidence interval to make decisions on predictor or
effect size differences from zero. The confidence interval that does not
include zero would be considered different from zero (to four decimal
places). We made no directional predictions.

## RQ1: Publisher Information.

```{r total-articles}
# updated 
total_num <- 510334
health_num <- 445301
physical_num <- 228194
social_num <- 26652
life_num <- 307514
```

*Number of articles*. The total number of articles included in this
analysis was `r total_num` including `r health_num` Health Sciences
articles, `r physical_num` Physical Sciences articles, `r social_num`
Social Sciences articles, and `r life_num` Life Sciences articles.
Articles could be classified into multiple categories. Figure
\@ref(fig:fig-pub-time) shows the number of articles published across
time for each of the four large subject areas.

```{r fig-pub-time, include = TRUE, fig.cap="Number of big-team science publications separated by four large subject areas across years. All four subject areas show an exponential number of publications in the last decade. ", fig.width=10, fig.height=6}
ggplot(DF$pub_time_count %>% 
         filter(SubjectArea != "Multidisciplinary") %>% 
         filter(Year < 2023), 
       aes(Year, count, color = SubjectArea)) + 
  theme_classic(base_size = 15) + 
  geom_point() + 
  scale_color_brewer(palette = "Spectral", name = "Subject Area") + 
  ylab("Number of Articles Per Year") + 
  xlab("Publication Year") + 
  theme(legend.position = "bottom")

ggsave(filename = "figure/figure_1_pub_time.png", width = 10, height = 6)
```

```{r total-journals}
# updated
journals <- 14924
health_journal <- 6559
physical_journal <- 5787
social_journal <- 2500
life_journal <- 4187
```

*Number of journals*. The number of distinct journals big team science
articles were published in was `r journals` with `r health_journal`
journals in Health Sciences, `r physical_journal` journals in Physical
Sciences, `r social_journal` journals in Social Sciences, and
`r life_journal` journals in Life Sciences. The descriptive statistics
for the Source Normalized Impact per Paper is presented in the
supplemental materials with a comparison for all papers.

## RQ2: Publication Information.

Publication interest area was summarized by the four large subject areas
creating a word cloud plot of the total number of publications within
the ASJCs. Figure \@ref(fig:fig-clouds) displays that the Health
Sciences tends to publish within medicine and oncology, with a
corresponding focus of cancer research and genetics for the Life
Sciences. The Physical Sciences was mostly dominated by physics
research, chemistry, and ecology. The BTS publications in the Social
Sciences are mostly within psychology, education, and health.

```{r make-clouds, eval = FALSE, warning = FALSE, echo = FALSE, message = FALSE}
### NOTE YOU WILL NEED TO RUN THIS ###
#DF$pub_time_subject$ASJC <- factor(DF$pub_time_subject$ASJC)
pub_total <- DF$pub_time_subject %>% 
  group_by(SubjectArea, ASJC) %>% 
  summarize(Count_Size = sum(count), .groups = "keep") %>% 
  filter(SubjectArea != "Multidisciplinary") %>% 
  left_join(DF$ASJC_codes %>% select(Name, Code), by = c("ASJC" = "Code"))

# health
health_cloud <- pub_total %>% 
  filter(SubjectArea == "Health Sciences") %>% 
  ungroup() %>%
  arrange(desc(Count_Size)) %>% 
  ggplot() + 
  geom_text_wordcloud_area(aes(label = Name, size = Count_Size), area_corr_power = TRUE, rm_outside = TRUE, shape = "square", perc_step = .001, grid_margin = .01) + 
  theme_minimal() + 
  scale_size_area(max_size = 15)

ggsave("figure/health_cloud.png", dpi = 300, width = 8,
       height = 4, units = "in")

# physical
physical_cloud <- pub_total %>% 
  filter(SubjectArea == "Physical Sciences") %>% 
  ungroup() %>%
  arrange(desc(Count_Size)) %>% 
  ggplot() + 
  geom_text_wordcloud_area(aes(label = Name, size = Count_Size), area_corr_power = TRUE, rm_outside = TRUE, shape = "square", perc_step = .001, grid_margin = .01) + 
  theme_minimal() + 
  scale_size_area(max_size = 15)

ggsave("figure/physical_cloud.png", dpi = 300, width = 8,
       height = 4, units = "in")

# life
life_cloud <- pub_total %>% 
  filter(SubjectArea == "Life Sciences") %>% 
  ungroup() %>%
  arrange(desc(Count_Size)) %>% 
  ggplot() + 
  geom_text_wordcloud_area(aes(label = Name, size = Count_Size), area_corr_power = TRUE, rm_outside = TRUE, shape = "square", perc_step = .001, grid_margin = .01) + 
  theme_minimal() + 
  scale_size_area(max_size = 15)

ggsave("figure/life_cloud.png", dpi = 300, width = 8,
       height = 4, units = "in")

# social
social_cloud <- pub_total %>% 
  filter(SubjectArea == "Social Sciences") %>% 
  ungroup() %>%
  arrange(desc(Count_Size)) %>% 
  ggplot() + 
  geom_text_wordcloud_area(aes(label = Name, size = Count_Size), area_corr_power = TRUE, rm_outside = TRUE, shape = "square", perc_step = .001, grid_margin = .01) + 
  theme_minimal() + 
  scale_size_area(max_size = 15)

ggsave("figure/social_cloud.png", dpi = 300, width = 8,
       height = 4, units = "in")
```

```{r fig-clouds, include = TRUE, fig.cap = "Journal Areas for Big-Team Science Publications by Subject Area. Larger words indicate more publications in those ASJC areas. ", fig.width=10, fig.height=6}

health_cloud <- fig("figure/health_cloud.png")
physical_cloud <- fig("figure/physical_cloud.png") 
life_cloud <- fig("figure/life_cloud.png") 
social_cloud <- fig("figure/social_cloud.png") 

health_cloud + ggtitle("Health Sciences") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
physical_cloud + ggtitle("Physical Sciences") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
life_cloud + ggtitle("Life Sciences") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
social_cloud + ggtitle("Social Sciences") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  plot_layout(ncol = 2, 
              nrow = 2)

ggsave(filename = "figure/figure_2_cloud.png", width = 10, height = 6)
```

## RQ3: Authors.

```{r total-authors}
# updated
total_authors <- 510334
avg_authors <- apa_num(49.30516877182394)
sd_authors <- apa_num(212.9786134634032)
min_authors <- 10
med_authors <- 18
max_authors <- 5568
```

The total number of unique authors across all publications was
`r total_authors`. The mean number of authors per publication was *M* =
`r avg_authors` (*SD* = `r sd_authors`, *Med* = `r med_authors`) with a
range of `r min_authors` to `r max_authors`. The median and average
number of authors by subject area are displayed in Figure
\@ref(fig:fig-author-year). In general, the average and median number of
authors increased over time, with the exception of the skew in the
Physical Sciences. Interestingly, the effect in the Physical Sciences
appears to be declining toward the general trends seen in other areas in
the last few decades.

```{r fig-author-year, include = TRUE, fig.cap="Number of authors included on big-team science papers per year by subject area. Given the large skew in the data, the left panel presents the median number of authors per manuscript, and the right panel presents the average number of authors per manuscript by year.", fig.width=10, fig.height=6}
avg_author_time <- 
  DF$author_time %>% 
  filter(SubjectArea != "Multidisciplinary") %>% 
  # filter(Number_Papers >= 3) %>% 
  mutate(low = (Average_Num_Authors - as.numeric(SD_Num_Authors)), 
         high = (Average_Num_Authors + as.numeric(SD_Num_Authors)))
  
# ggplot(avg_author_time, aes(Year, Med_Num_Authors)) + 
#   theme_classic() + 
#   geom_point(aes(size = Number_Papers)) + 
#   geom_point(aes(Year, Average_Num_Authors, color = "red")) + 
#   #geom_pointrange(aes(ymin = low, ymax = high)) + 
#   facet_wrap(~SubjectArea) + 
#   ylab("Average Number of Authors") + 
#   xlab("Publication Year") + 
#   theme(legend.position = "bottom") + 
#   guides(color = "none") + 
#   scale_size_continuous(name = "Number Papers")

median_authors <- 
  ggplot(avg_author_time, aes(Year, Med_Num_Authors, color = SubjectArea)) + 
  theme_classic(base_size = 15) + 
  geom_point() + 
    ylab("Median Number of Authors") + 
    xlab("Publication Year") 

mean_authors <- 
  ggplot(avg_author_time, aes(Year, Average_Num_Authors, color = SubjectArea)) + 
  theme_classic(base_size = 15) + 
  geom_point() + 
    ylab("Average Number of Authors") + 
    xlab("Publication Year") 

median_authors + 
  scale_color_brewer(palette = "Spectral", name = "Subject Area") + 
  mean_authors + 
  scale_color_brewer(palette = "Spectral", name = "Subject Area") + 
  plot_layout(guides = "collect") & theme(legend.position = 'bottom')

ggsave(filename = "figure/figure_3_num_authors.png", width = 10, height = 6)
```

***Career Length***.

Figure \@ref(fig:fig-career) portrays the average career length for
authors involved in BTS publications across years. Career length was
defined as the year of first publication minus the current year, and
higher numbers mean longer careers. To analyze trends over time, we
calculated the average career length for each publication (i.e., average
author career lengths to create one score for each paper) and analyzed a
regression analysis using career length to predict year of publication.
In order to show variance between individuals, we calculated the
standard deviation of career length for each publication and used this
variance as an additional predictor.

Negative career length slopes would indicate more young scholars in
later years (i.e., lower average career length as time increases).
Positive career length slopes would indicate older scholars in later
years (i.e., higher average career length as time increases). Negative
career variance slopes imply that variability decreases over the years,
so the average career length is more homogeneous. Positive career length
slopes imply that variability increases over the years, so the average
career length is varied across individuals (i.e., different stages of
scholars). Figure \@ref(fig:fig-heatmap) displays the results for all
regression analyses to compare coefficient strength across and within
each hypothesis.

All values for these analyses were different from zero. The slopes for
the average career length were negative for all four subject areas,
indicating a trend toward younger scientist involvement over time for
each area, with the strongest effect in the Physical Sciences. The
coefficient for variability in career length was also negative for each
of the four subject areas with the highest in the Physical Sciences and
lowest in the Life Sciences. This result indicates a decrease in the
variability of career lengths over time, likely from two sources: 1)
more publications with more authors, thus, lowering variance
estimations, and 2) more young scholars overall. The effect sizes for
this analysis were surprisingly large ranging from $R^2$ = .25 to .47.
All values and their confidence intervals can be found on our OSF page.

```{r fig-career, include = TRUE,  warning = FALSE, message = FALSE, fig.cap = "Average career length for big-team science authors. Larger dots indicate more variability in career length for authors by averaging the standard deviation in career length for each manuscript within a year. The data has been filtered to at least 10 publications in a year for this graph.", fig.width=10, fig.height=6}
temp <- ggplot(DF$career_time %>% 
         filter(SubjectArea != "Multidisciplinary") %>% 
         filter(num_papers >= 10) %>% 
         filter(Year < 2024), 
       aes(Year, avg_career, color = SubjectArea)) +
  theme_classic(base_size = 15) + 
  geom_point(aes(size = sd_career)) +
  # geom_point() + 
  # facet_wrap(~SubjectArea) + 
  theme(legend.position = "bottom") + 
  ylab("Average Career Length") +
  xlab("Year of Publication") + 
  scale_color_brewer(palette = "Spectral", name = "Subject Area") +
  guides(size = "none")  
  #scale_size_continuous(name = "Number Papers")

suppressWarnings(suppressMessages(temp))

ggsave(filename = "figure/figure_4_career.png", width = 10, height = 6)
```

```{r career-results, include = FALSE}

label <- c("Physical", "Social", "Health", "Life")
avg_b_values <- c(-0.692014, -0.365357, -0.451827, -0.508350)
avg_se_values <- c(0.002727, 0.005525, 0.001348, 0.001786)
sd_b_values <- c(-0.265538, -0.097108, -0.096730, -0.013958)
sd_se_values <- c(0.007018, 0.013409, 0.003451, 0.004523)
r2_values <- c(0.465446, 0.254312, 0.303781, 0.350923)
sample_size <- total_num

r2_low <- 1:length(r2_values)
r2_high <- 1:length(r2_values)
for (i in 1:length(r2_values)){
  temp <- ci.R2(R2 = r2_values[i], 1, sample_size)
  r2_low[i] <- temp$Lower.Conf.Limit.R2
  r2_high[i] <- temp$Upper.Conf.Limit.R2
}

graph_data <- data.frame(
  "label" = label,
  "estimate" = avg_b_values,
  "type" = "Coefficient",
  "low" = avg_b_values - qt(.025, sample_size, lower.tail = F)*avg_se_values,
  "high" = avg_b_values + qt(.025, sample_size, lower.tail = F)*avg_se_values) %>% 
    bind_rows(
    data.frame(
    "label" = label,
    "estimate" = sd_b_values,
    "type" = "SD Coefficient",
    "low" = sd_b_values - qt(.025, sample_size, lower.tail = F)*sd_se_values,
    "high" = sd_b_values + qt(.025, sample_size, lower.tail = F)*sd_se_values) 
    ) %>% 
  bind_rows(
    data.frame(  
      "label" = label, 
      "estimate" = r2_values,
      "type" = "Effect Size",
      "low" = r2_low,
      "high" = r2_high)
  )

graph_data$type <- factor(
  graph_data$type, 
  levels = c("Coefficient", "SD Coefficient", "Effect Size")
)

graph_data$analysis <- "Career"

# ggplot(graph_data, aes(label, estimate)) + 
#   geom_point() +
#   geom_pointrange(aes(ymin = low, ymax = high)) +
#   theme_classic() + 
#   facet_wrap(~type, labeller  = labeller(type = label_expressions(strip_labels))) + 
#   geom_hline(yintercept = 0) + 
#   coord_flip() + 
#   xlab("Subject Area") + 
#   ylab("")
```

```{r pub-results, include = FALSE}

label <- c("Physical", "Social", "Health", "Life")
avg_b_values <- c(0.004248, -0.027315, -0.021713, -0.009466)
avg_se_values <- c(0.000179, 0.001073, 0.000211, 0.000213)
sd_b_values <- c(-0.021552, 0.016810, 0.010139, -0.000378)
sd_se_values <- c(0.000241, 0.000921, 0.000198, 0.000235)
r2_values <- c(0.135965, 0.035968, 0.048999, 0.030748)
sample_size <- total_num

r2_low <- 1:length(r2_values)
r2_high <- 1:length(r2_values)
for (i in 1:length(r2_values)){
  temp <- ci.R2(R2 = r2_values[i], 1, sample_size)
  r2_low[i] <- temp$Lower.Conf.Limit.R2
  r2_high[i] <- temp$Upper.Conf.Limit.R2
}

graph_data_2 <- data.frame(
  "label" = label,
  "estimate" = avg_b_values,
  "type" = "Coefficient",
  "low" = avg_b_values - qt(.025, sample_size, lower.tail = F)*avg_se_values,
  "high" = avg_b_values + qt(.025, sample_size, lower.tail = F)*avg_se_values) %>% 
    bind_rows(
    data.frame(
    "label" = label,
    "estimate" = sd_b_values,
    "type" = "SD Coefficient",
    "low" = sd_b_values - qt(.025, sample_size, lower.tail = F)*sd_se_values,
    "high" = sd_b_values + qt(.025, sample_size, lower.tail = F)*sd_se_values) 
    ) %>% 
  bind_rows(
    data.frame(  
      "label" = label, 
      "estimate" = r2_values,
      "type" = "Effect Size",
      "low" = r2_low,
      "high" = r2_high)
  )

graph_data_2$type <- factor(
  graph_data_2$type, 
  levels = c("Coefficient", "SD Coefficient", "Effect Size")
)

graph_data_2$analysis <- "Publication"

# ggplot(graph_data, aes(label, estimate)) + 
#   geom_point() +
#   geom_pointrange(aes(ymin = low, ymax = high)) +
#   theme_classic() + 
#   facet_wrap(~type, labeller  = labeller(type = label_expressions(strip_labels))) + 
#   geom_hline(yintercept = 0) + 
#   coord_flip() + 
#   xlab("Subject Area") + 
#   ylab("")
```

```{r diversity-results, include = FALSE}

label <- c("Physical", "Social", "Health", "Life")
b_values <- c(0.002175, 0.033175, 0.016824, 0.008029)
se_values <- c(0.002578, 0.006039, 0.001150, 0.001476)
r2_values <- c(0.000006, 0.001542, 0.000708, 0.000170)
sample_size <- total_num

r2_low <- 1:length(r2_values)
r2_high <- 1:length(r2_values)
for (i in 1:length(r2_values)){
  temp <- ci.R2(R2 = r2_values[i], 1, sample_size)
  r2_low[i] <- temp$Lower.Conf.Limit.R2
  r2_high[i] <- temp$Upper.Conf.Limit.R2
}

graph_data_3 <- data.frame(
  "label" = label,
  "estimate" = b_values,
  "type" = "Coefficient",
  "low" = b_values - qt(.025, sample_size, lower.tail = F)*se_values,
  "high" = b_values + qt(.025, sample_size, lower.tail = F)*se_values) %>% 
  bind_rows(
    data.frame(  
      "label" = label, 
      "estimate" = r2_values,
      "type" = "Effect Size",
      "low" = r2_low,
      "high" = r2_high)
  )

graph_data_3$type <- factor(
  graph_data_3$type,
  levels = c("Coefficient", "Effect Size")
)

graph_data_3$analysis <- "Regions"

# ggplot(graph_data, aes(label, estimate)) + 
#   geom_point() +
#   geom_pointrange(aes(ymin = low, ymax = high)) +
#   theme_classic() + 
#   facet_wrap(~type, labeller  = labeller(type = label_expressions(strip_labels_2))) + 
#   geom_hline(yintercept = 0) + 
#   coord_flip() + 
#   xlab("Subject Area") + 
#   ylab("")
```

```{r fig-heatmap, include = TRUE, fig.cap="Heatmap results of regression analyses for career length, number of publications, and geopolitical diversity within the region. The top figure represents all results together for comparison across analyses. The bottom row represents individual heatmaps for each hypothesis to distinguish small differences between subject areas for those research questions. Non-significant results are indicated with NS on the plot.", warning = FALSE, message = FALSE, fig.width=10, fig.height=6}
graph_overall <- graph_data %>% 
  bind_rows(graph_data_2) %>% 
  bind_rows(graph_data_3) %>% 
  mutate(type = factor(type, levels = c("Effect Size", "SD Coefficient", "Coefficient"))) %>% 
  mutate(Estimate = estimate) %>% 
  mutate(heat_label = ifelse(
    low < .00001 & high > .00001, "NS", ""
  ))
  
heat_results <- ggplot(graph_overall, aes(label, type, fill = Estimate)) + 
  geom_tile(color = "white", lwd = 1.5, linetype = 1) +
  coord_fixed() + 
  scale_y_discrete(labels  = c(TeX("$R^2$"), TeX("$b_{SD}$"), TeX("$b$"))) + 
  ylab("") + 
  xlab("") + 
  facet_wrap(~analysis) + 
  theme_classic(base_size = 15) + 
  theme(axis.text.x = element_text(angle = 60, vjust = .5), 
        legend.position = "right", 
        legend.key.size = unit(.75, 'cm')) + 
  scale_fill_distiller(palette = "Spectral") + 
  geom_text(aes(label=heat_label))


# heat_results

heat_results_1 <- ggplot(graph_overall %>% 
                           filter(analysis == "Career"), 
                         aes(label, type, fill = Estimate)) + 
  geom_tile(color = "white", lwd = 1.5, linetype = 1) +
  coord_fixed() + 
  scale_y_discrete(labels  = c(TeX("$R^2$"), TeX("$b_{SD}$"), TeX("$b_M$"))) + 
  ylab("") + 
  xlab("") + 
  theme_classic(base_size = 15) + 
  theme(axis.text.x = element_text(angle = 60, vjust = .5), 
        legend.position = "right") + 
  scale_fill_distiller(palette = "RdBu") + 
  ggtitle("Career")  + 
  geom_text(aes(label=heat_label))

heat_results_2 <- ggplot(graph_overall %>% 
                           filter(analysis == "Publication"), 
                         aes(label, type, fill = Estimate)) + 
  geom_tile(color = "white", lwd = 1.5, linetype = 1) +
  coord_fixed() + 
  scale_y_discrete(labels  = c(TeX("$R^2$"), TeX("$b_{SD}$"), TeX("$b_M$"))) + 
  ylab("") + 
  xlab("") + 
  theme_classic(base_size = 15) + 
  theme(axis.text.x = element_text(angle = 60, vjust = .5), 
        legend.position = "right") + 
  scale_fill_distiller(palette = "PuOr") + 
  ggtitle("Publication") + 
  geom_text(aes(label=heat_label))

heat_results_3 <- ggplot(graph_overall %>% 
                           filter(analysis == "Regions"), 
                         aes(label, type, fill = Estimate)) + 
  geom_tile(color = "white", lwd = 1.5, linetype = 1) +
  coord_fixed() + 
  scale_y_discrete(labels  = c(TeX("$R^2$"), TeX("$b$"))) + 
  ylab("") + 
  xlab("") + 
  theme_classic(base_size = 15) + 
  theme(axis.text.x = element_text(angle = 60, vjust = .5), 
        legend.position = "right") + 
  scale_fill_distiller(palette = "PiYG") +
  ggtitle("Regions") + 
  geom_text(aes(label=heat_label))

layout <- "
AAA
BCD
"
suppressMessages(suppressWarnings(heat_results + 
  heat_results_1 + heat_results_2 + heat_results_3 + 
  plot_layout(design = layout)))

ggsave(filename = "figure/figure_5_heatmap.png", width = 10, height = 6, units = "in")
```

***Institution***.

```{r total-aff}
# updated
affs <- 463876
```

The total number of unique affiliation across all papers was `r affs`.

***Publication Metrics***.

```{r pub-hindex}
avg_pub_count_author	<- apa_num(38.368910766896065)
std_pub_count_author <- apa_num(102.53740454680472)

avg_pub_count_paper <- apa_num(162.50184385336053)
sd_pub_count_paper <- apa_num(155.1665533053519)
avg_SD_pub_count_paper <- apa_num(164.27249797983876)
SD_SD_pub_count_paper <- apa_num(127.20989934008757)

avg_HIndex <- apa_num(33.64589690529209)
std_HIndex <- apa_num(127.33565834550778)
med_HIndex <- apa_num(8.0)

avg_of_avg_HIndex <- apa_num(198.87318851400775)
std_of_avg_HIndex <- apa_num(248.7847084313958)
avg_of_std_HIndex <- apa_num(211.7985924228093)
std_of_std_HIndex <- apa_num(238.53141146314053)
med_of_med_HIndex <- apa_num(68.0)
```

The average number of publications by authors on big team science papers
is *M* = `r avg_pub_count_author` (*SD* = `r std_pub_count_author`). The
publication counts were averaged across authors for each publication,
and then these average publication counts were averaged across
publications *M* = `r avg_pub_count_paper` (*SD* =
`r sd_pub_count_paper`). The average variability (i.e., the average
standard deviation with authors of a manuscript) with publication counts
of a paper was $M_{SD}$ = `r avg_SD_pub_count_paper` ($SD_{SD}$ =
`r SD_SD_pub_count_paper`).

The same process was completed with *h*-index for each author and
publication. The average *h*-index for authors overall was *M* =
`r avg_HIndex` (*SD* = `r std_HIndex`, *Med* = `r med_HIndex`). The
average *h*-index for publications was *M* = `r avg_of_avg_HIndex` (*SD*
= `r std_of_avg_HIndex`), and the variability of *h*-index across
manuscripts was $M_{SD}$ = `r avg_of_std_HIndex` ($SD_{SD}$ =
`r std_of_std_HIndex`, $Med_{Med}$ = `r med_of_med_HIndex`).

We used the same analyses described in the career length section to
analyze trends over time. An increasing slope over time indicates that
individuals who are publishing more are more represented in BTS over
time (i.e., increasing numbers of scholars with higher publication
rates), while a negative slope indicates more researchers with less
publications. A positive slope for the standard deviation of publication
metrics indicates increasing variance over time (i.e., more diversity in
the individual publication rates), while a negative slope would indicate
less diversity in researchers over time. While publication rates do not
represent value as a researcher, they are often used in hiring and
promotion decisions, and we used this variable as a proxy to gauge the
diversity in scholars represented in big teams. As shown in Figure
\@ref(fig:fig-heatmap) publication metrics were generally negative for
the average publication metrics, indicating more scholars over time with
lower numbers of publications with the strongest effects in Health and
Social Sciences. The variability of publication counts was not
significant for the Life Sciences but was negative for the Physical
Sciences (less variability over time) and positive for Social and Health
Sciences (more variability and over time). This result indicates that
the Physical Sciences are trending toward scholars with less
publications but also less diverse in number of publications, while the
Health and Social Sciences see more diversity in publication counts and
less published scholars overall.

***Geopolitical Regions***.

```{r geo-map}
# serbia has changed codes
# updated but needs work
DF$geo_country$affiliation_tag_country <- toupper(DF$geo_country$affiliation_tag_country)
DF$geo_country <- subset(DF$geo_country, affiliation_tag_country != "NONE")
DF$geo_country$affiliation_tag_country[DF$geo_country$affiliation_tag_country == "SCG"] <- "SRB"

DF$geo_country <- DF$geo_country %>% 
  group_by(affiliation_tag_country) %>% 
  summarize(count = sum(count),
            count_all = sum(all_count))

# convert country code to region code
# this will warn you about the ones that have multiple countries 
# create a world map 
world_map <- map_data(map = "world")
world_map$orig_region <- world_map$region
world_map$region <- iso.alpha(world_map$region, n = 3)
world_map <- subset(world_map, region != "ATA")
  
# maybe try binning
DF$geo_country$count_binned <- if_else(
  DF$geo_country$count >= 1000000, "1,000,000+", 
  if_else(
    DF$geo_country$count >= 500000 & DF$geo_country$count < 1000000, "500,000-999,999",
    if_else(
      DF$geo_country$count >= 100000 & DF$geo_country$count < 500000, "100,000-499,999",
      if_else(
        DF$geo_country$count >= 10000 & DF$geo_country$count < 100000, "10,000-99,999", 
        if_else(
          DF$geo_country$count < 10000 & DF$geo_country$count >= 5000, "5,000-9,999",
          if_else(
            DF$geo_country$count < 5000 & DF$geo_country$count >= 1000, "1,000-4,999",
            if_else(
              DF$geo_country$count < 1000 & DF$geo_country$count >= 100, "100-999",
              "< 100"
            )
          )
        )
      )
    )
  )
)

DF$geo_country$count_binned <- factor(DF$geo_country$count_binned, 
                                   levels = unique(DF$geo_country$count_binned))

DF$geo_country$count_binned <- factor(DF$geo_country$count_binned, 
                                      levels = c("< 100", 
                                                 "100-999", 
                                                 "1,000-4,999", 
                                                 "5,000-9,999", 
                                                 "10,000-99,999",
                                                 "100,000-499,999",
                                                 "500,000-999,999",
                                                 "1,000,000+"))

# map of binned data 
bin_country <- ggplot(DF$geo_country) +
  geom_map(aes(map_id = affiliation_tag_country, fill = count_binned), map = world_map) +
  geom_polygon(data = world_map, 
               aes(x = long, y = lat, group = group), 
               colour = 'black', fill = NA) + 
  theme_void(base_size = 15) + 
  # scale_fill_manual(name = "Sample Size",
  #                   values = c( "black", "#323232", "#646464","#969696","#c8c8c8")) 
  scale_fill_brewer(name = "Sample Size", palette = "Spectral", drop = FALSE)

# Warning: Some values were not matched unambiguously: ANT, ATA, BUR, BUX, BYS, CAI, CSK, CZH, DDR, EUE, HVO, PCI, ROM, SUN, SUX, TWN, UNO, YMD, YUG, ZAR

# tree map
DF$geo_country$un_region_sub <- suppressWarnings(
  countrycode(
  sourcevar = DF$geo_country$affiliation_tag_country,
  origin = 'iso3c', 
  destination = 'un.regionsub.name')
)

DF$geo_country$un_region <- suppressWarnings(
  countrycode(
  sourcevar = DF$geo_country$affiliation_tag_country,
  origin = 'iso3c', 
  destination = 'un.region.name')
)

DF$geo_country$un_region[DF$geo_country$affiliation_tag_country == "TWN"] <- "Asia"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "TWN"] <- "Eastern Asia"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "ANT"] <- "Western Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "BUR"] <- "Western Africa"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "BYS"] <- "Eastern Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "CSK"] <- "Eastern Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "DOR"] <- "Eastern Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "HVO"] <- "Sub-Saharan Africa"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "PCI"] <- "Eastern Asia"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "ROM"] <- "Eastern Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "SUN"] <- "Eastern Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "YMD"] <- "Western Asia"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "YUG"] <- "Eastern Europe"
DF$geo_country$un_region_sub[DF$geo_country$affiliation_tag_country == "ZAR"] <- "Sub-Saharan Africa"

DF$geo_country <- DF$geo_country %>% 
  na.omit()

tree <- ggplot(DF$geo_country, aes(area = count, fill = count_binned,
               label = affiliation_tag_country, subgroup = un_region_sub)) +
  geom_treemap() +
  geom_treemap_subgroup_border(colour = "white", size = 5) +
  # geom_treemap_subgroup_text(place = "top", grow = TRUE,
  #                            alpha = 0.25, colour = "black",
  #                            fontface = "italic") +
  geom_treemap_text(colour = "black", place = "centre",
                    size = 15, grow = FALSE) +  
  # scale_fill_manual(name = "Sample Size",
  #                   values = c("#c8c8c8", "#969696", "#646464", "#323232", "black")) 
  scale_fill_brewer(name = "Sample Size", palette = "Spectral", drop = FALSE)
  # scale_fill_gradient(name = "Sample Size",
  #                     low = "#c8c8c8", 
  #                     high = "#323232") 
```

```{r geo-map-all}
# maybe try binning
DF$geo_country$count_binned_all <- if_else(
  DF$geo_country$count_all >= 1000000, "1,000,000+", 
  if_else(
    DF$geo_country$count_all >= 500000 & DF$geo_country$count_all < 1000000, "500,000-999,999",
    if_else(
      DF$geo_country$count_all >= 100000 & DF$geo_country$count_all < 500000, "100,000-499,999",
      if_else(
        DF$geo_country$count_all >= 10000 & DF$geo_country$count_all < 100000, "10,000-99,999", 
        if_else(
          DF$geo_country$count_all < 10000 & DF$geo_country$count_all >= 5000, "5,000-9,999",
          if_else(
            DF$geo_country$count_all < 5000 & DF$geo_country$count_all >= 1000, "1,000-4,999",
            if_else(
              DF$geo_country$count_all < 1000 & DF$geo_country$count_all >= 100, "100-999",
              "< 100"
            )
          )
        )
      )
    )
  )
)

DF$geo_country$count_binned_all <- factor(DF$geo_country$count_binned_all, 
                                   levels = unique(DF$geo_country$count_binned_all))

DF$geo_country$count_binned_all <- factor(DF$geo_country$count_binned_all, 
                                      levels = c("< 100", 
                                                 "100-999", 
                                                 "1,000-4,999", 
                                                 "5,000-9,999", 
                                                 "10,000-99,999",
                                                 "100,000-499,999",
                                                 "500,000-999,999",
                                                 "1,000,000+"))

# map of binned data 
bin_country_all <- ggplot(DF$geo_country) +
  geom_map(aes(map_id = affiliation_tag_country, fill = count_binned_all), map = world_map) +
  geom_polygon(data = world_map, 
               aes(x = long, y = lat, group = group), 
               colour = 'black', fill = NA) + 
  theme_void(base_size = 15) + 
  # scale_fill_manual(name = "Sample Size",
  #                   values = c( "black", "#323232", "#646464","#969696","#c8c8c8")) 
  scale_fill_brewer(name = "Sample Size", palette = "Spectral", drop = FALSE)

tree_all <- ggplot(DF$geo_country, aes(area = count_all, fill = count_binned_all,
               label = affiliation_tag_country, subgroup = un_region_sub)) +
  geom_treemap() +
  geom_treemap_subgroup_border(colour = "white", size = 5) +
  # geom_treemap_subgroup_text(place = "top", grow = TRUE,
  #                            alpha = 0.25, colour = "black",
  #                            fontface = "italic") +
  geom_treemap_text(colour = "black", place = "centre",
                    size = 15, grow = FALSE) +  
  # scale_fill_manual(name = "Sample Size",
  #                   values = c("#c8c8c8", "#969696", "#646464", "#323232", "black")) 
  scale_fill_brewer(name = "Sample Size", palette = "Spectral", drop = FALSE)
  # scale_fill_gradient(name = "Sample Size",
  #                     low = "#c8c8c8", 
  #                     high = "#323232") 
```

```{r fig-map-both, include = TRUE, fig.cap="Geopolitical regions represented in big-team science publications versus all publications. The mosaic plot is grouped by UN subregion with the largest number of publications on the left and smallest on the top right. ", fig.width=10, fig.height=6}
bin_country + ggtitle("Big-Team Publication Map") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme(legend.position = "none") + 
tree + ggtitle("Big-Team Publication Mosiac Chart") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  guides(fill = "none") + 
bin_country_all + ggtitle("All Publications Map") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  guides(fill = "none") + 
tree_all + ggtitle("All Publications Mosiac Chart") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  guides(fill = "none") + 
  plot_layout(ncol = 2, 
              nrow = 2) + 
  plot_layout(guides = "collect") & theme(legend.position = 'bottom')

ggsave(filename = "figure/figure_6_map.png", width = 10, height = 6, units = "in")
```

Author geopolitical region is displayed in Figure
\@ref(fig:fig-map-both). Big team publications appear to be led by North
America and Western Europe, while all publications are led by North
America and East Asia. To understand the change in representation
diversity, we examined if the number of regions in a publication is
predicted by the year of publication. Increasing diversity would be
represented by a positive slope, while decreasing diversity would be
represented by a negative slope. As shown in Figure
\@ref(fig:fig-heatmap), the Physical Sciences do not show a trend of
change in representation, while all other sciences showed a positive
effect increasing in the number of geopolitical regions authors
represent on publications.

Last, we examined the differences in representation for corresponding
author sets versus all other authors. For papers with 10 to 49 authors,
we used the three first authors and the last author to compare against
other authors. For 50 to 99 authors, five first authors plus last were
used, and for all papers with more than 100 authors, we used ten first
authors and the last author as the corresponding author set. We then
calculated the frequencies of each of the UN Sub-Regions for
corresponding authors versus all other authors, converting these values
to proportions. Given the expected small sample sizes of these
contingency tables, we grouped together titles based on the year of
publication. For each grouping, we then calculated the effect size of
the differences in frequencies comparing corresponding authors to all
other authors. Since this data is categorical, we used Cramer's *V* to
represent the effect size. If the effect size includes zero in its
confidence interval (to four decimal places), this result will imply
that first and all other authors represent the same pattern of UN
Sub-Region diversity. Any confidence interval that does include zero
represents a difference in diversity.

```{r small-effects, warning = FALSE}
DF$small_first_gp <- DF$small_first_gp %>% 
  filter(aff_un != "other") %>% 
  pivot_wider(id_cols = Year, 
              names_from = aff_un, 
              values_from = count,
              values_fill = 0)

DF$small_other_gp <- DF$small_other_gp %>% 
  filter(aff_un != "other") %>% 
  pivot_wider(id_cols = Year, 
              names_from = aff_un, 
              values_from = count,
              values_fill = 0) %>% 
  select(colnames(DF$small_first_gp))

small_effect <- data.frame(
  year = 1:length(unique(DF$small_first_gp$Year)),
  v = 1:length(unique(DF$small_first_gp$Year)),
  low = 1:length(unique(DF$small_first_gp$Year)),
  high = 1:length(unique(DF$small_first_gp$Year))
)
i <- 1
for (year in unique(DF$small_first_gp$Year)){
  temp_table <- DF$small_first_gp %>% filter(Year == year) %>% select(-Year) %>% 
    bind_rows(DF$small_other_gp %>% filter(Year == year) %>% select(-Year))
  
  col_total <- colSums(temp_table)
  temp_table <- temp_table %>% 
    select(names(col_total)[col_total > 0])
  temp <- suppressWarnings(chisq.test(as.matrix(temp_table)))
  
  tryCatch(mote_temp <- v.chi.sq(x2 = temp$statistic, n = sum(temp_table), 
                        r = nrow(temp_table), c = ncol(temp_table), 
                        a = .05), 
       warning = function(w) { 
         mote_temp <<- v.chi.sq(x2 = temp$statistic, n = sum(temp_table), 
                        r = nrow(temp_table), c = ncol(temp_table), 
                        a = .05)
         mote_temp$vlow <<- 0
  }
  )
  
  small_effect$year[i] <- year
  small_effect$v[i] <- mote_temp$v
  small_effect$low[i] <- mote_temp$vlow
  small_effect$high[i] <- mote_temp$vhigh
  small_effect$people[i] <- mote_temp$n
  i <- i + 1
}

small_effect$high[is.na(small_effect$high)] <- 0
small_effect <- 
  small_effect %>% 
  filter(v != Inf)

small_dot <- ggplot(small_effect, aes(year,v)) + 
  geom_point(aes(size = people)) + 
  theme_classic(base_size = 15) + 
  geom_pointrange(aes(ymin = low, ymax = high)) + 
  xlab("Year") + 
  ylab(expression(phi)) + 
  scale_size_continuous(name = "Num Authors")

DF_decade <- DF$small_first_gp %>% 
  mutate(who = "F") %>% 
  bind_rows(
    DF$small_other_gp %>% 
      mutate(who = "O")
  ) %>% 
  mutate(Decade = ifelse(Year < 1990, "1980s", 
                         ifelse(Year < 2000, "1990s", 
                                ifelse(Year < 2010, "2000s", 
                                       ifelse(Year < 2020, "2010s", "2020s"))))) %>% 
  group_by(who, Decade) %>% 
  summarize_all(sum) %>% 
  pivot_longer(cols = -c(who, Decade, Year),
               names_to = "Country", 
               values_to = "Count")

# North America, Africa (combine), NWS Europe, Eastern Asia, Latin America, Rest of Europe, Rest of Asia, Everything Else 

DF_decade$Country_2 <- DF_decade$Country
DF_decade$Country_2 <- gsub(".*Africa.*", "Africa", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Northern Europe|Southern Europe|Western Europe", "NWS Europe", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("South-Eastern Europe|Eastern Europe", "ESE Europe", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Central Asia|South-Eastern Asia|Southern Asia|Western Asia", "Asia", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Melanesia|Mirconesia|New zealand and Australia|Polynesia", "Other", DF_decade$Country_2)

DF_decade$Country_2 <- factor(DF_decade$Country_2, 
                              levels = c("Africa", "Asia", "Eastern Asia", 
                                         "ESE Europe", 
                                         "Latin America and the Caribbean",
                                         "North America", 
                                         "NWS Europe", "Other"))
DF_decade_sm <- DF_decade %>% 
  group_by(Country_2, Decade, who) %>% 
  summarize(Count = sum(Count), .groups = "keep")

small_author <- ggplot(DF_decade_sm, aes(who, Count, fill = Country_2)) + 
    geom_bar(position="fill", stat="identity", color = "black") + 
  theme_classic(base_size = 15) + 
  facet_grid(~Decade) + 
  xlab("Author Type") + 
  ylab("Percent of Authors") + 
  scale_fill_brewer(name = "Region", palette = "Spectral", drop = FALSE)
```

```{r medium-effects, warning = FALSE}
DF$medium_first_gp <- DF$medium_first_gp %>% 
  filter(aff_un != "other") %>% 
  pivot_wider(id_cols = Year, 
              names_from = aff_un, 
              values_from = count,
              values_fill = 0)

DF$medium_other_gp <- DF$medium_other_gp %>% 
  filter(aff_un != "other") %>% 
  pivot_wider(id_cols = Year, 
              names_from = aff_un, 
              values_from = count,
              values_fill = 0) %>% 
  select(colnames(DF$medium_first_gp))

medium_effect <- data.frame(
  year = 1:length(unique(DF$medium_first_gp$Year)),
  v = 1:length(unique(DF$medium_first_gp$Year)),
  low = 1:length(unique(DF$medium_first_gp$Year)),
  high = 1:length(unique(DF$medium_first_gp$Year))
)
i <- 1
for (year in unique(DF$medium_first_gp$Year)){
  temp_table <- DF$medium_first_gp %>% filter(Year == year) %>% select(-Year) %>% 
    bind_rows(DF$medium_other_gp %>% filter(Year == year) %>% select(-Year))
  
  col_total <- colSums(temp_table)
  temp_table <- temp_table %>% 
    select(names(col_total)[col_total > 0])
  temp <- suppressWarnings(chisq.test(as.matrix(temp_table)))
  tryCatch(mote_temp <- v.chi.sq(x2 = temp$statistic, n = sum(temp_table), 
                        r = nrow(temp_table), c = ncol(temp_table), 
                        a = .05), 
       warning = function(w) { 
         mote_temp <<- v.chi.sq(x2 = temp$statistic, n = sum(temp_table), 
                        r = nrow(temp_table), c = ncol(temp_table), 
                        a = .05)
         mote_temp$vlow <<- 0
  }
  )
  medium_effect$year[i] <- year
  medium_effect$v[i] <- mote_temp$v
  medium_effect$low[i] <- mote_temp$vlow
  medium_effect$high[i] <- mote_temp$vhigh
  medium_effect$people[i] <- mote_temp$n
  i <- i + 1
}

medium_effect$high[is.na(medium_effect$high)] <- 0
medium_effect <- 
  medium_effect %>% 
  filter(v != Inf)

medium_dot <- ggplot(medium_effect, aes(year,v)) + 
  geom_point(aes(size = people)) + 
  theme_classic(base_size = 15) + 
  geom_pointrange(aes(ymin = low, ymax = high)) + 
  xlab("Year") + 
  ylab(expression(phi)) + 
  scale_size_continuous(name = "Num Authors")

DF_decade <- DF$medium_first_gp %>% 
  mutate(who = "F") %>% 
  bind_rows(
    DF$medium_other_gp %>% 
      mutate(who = "O")
  ) %>% 
  mutate(Decade = ifelse(Year < 1990, "1980s", 
                         ifelse(Year < 2000, "1990s", 
                                ifelse(Year < 2010, "2000s", 
                                       ifelse(Year < 2020, "2010s", "2020s"))))) %>% 
  group_by(who, Decade) %>% 
  summarize_all(sum) %>% 
  pivot_longer(cols = -c(who, Decade, Year),
               names_to = "Country", 
               values_to = "Count")

# North America, Africa (combine), NWS Europe, Eastern Asia, Latin America, Rest of Europe, Rest of Asia, Everything Else 

DF_decade$Country_2 <- DF_decade$Country
DF_decade$Country_2 <- gsub(".*Africa.*", "Africa", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Northern Europe|Southern Europe|Western Europe", "NWS Europe", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("South-Eastern Europe|Eastern Europe", "ESE Europe", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Central Asia|South-Eastern Asia|Southern Asia|Western Asia", "Asia", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Melanesia|Mirconesia|New zealand and Australia|Polynesia", "Other", DF_decade$Country_2)

DF_decade$Country_2 <- factor(DF_decade$Country_2, 
                              levels = c("Africa", "Asia", "Eastern Asia", 
                                         "ESE Europe", 
                                         "Latin America and the Caribbean",
                                         "North America", 
                                         "NWS Europe", "Other"))

DF_decade_sm <- DF_decade %>% 
  group_by(Country_2, Decade, who) %>% 
  summarize(Count = sum(Count), .groups = "keep")

medium_author <- ggplot(DF_decade_sm, aes(who, Count, fill = Country_2)) + 
    geom_bar(position="fill", stat="identity", color = "black") + 
  theme_classic(base_size = 15) + 
  facet_grid(~Decade) + 
  xlab("Author Type") + 
  ylab("Percent of Authors") + 
  scale_fill_brewer(name = "Region", palette = "Spectral", drop = FALSE)
```

```{r large-effects, warning = FALSE}
DF$large_first_gp <- DF$large_first_gp %>% 
  filter(aff_un != "other") %>% 
  pivot_wider(id_cols = Year, 
              names_from = aff_un, 
              values_from = count,
              values_fill = 0)

DF$large_other_gp <- DF$large_other_gp %>% 
  filter(aff_un != "other") %>% 
  pivot_wider(id_cols = Year, 
              names_from = aff_un, 
              values_from = count,
              values_fill = 0) %>% 
  select(colnames(DF$large_first_gp))

large_effect <- data.frame(
  year = 1:length(unique(DF$large_first_gp$Year)),
  v = 1:length(unique(DF$large_first_gp$Year)),
  low = 1:length(unique(DF$large_first_gp$Year)),
  high = 1:length(unique(DF$large_first_gp$Year))
)
i <- 1
for (year in unique(DF$large_first_gp$Year)){
  temp_table <- DF$large_first_gp %>% filter(Year == year) %>% select(-Year) %>% 
    bind_rows(DF$large_other_gp %>% filter(Year == year) %>% select(-Year))
  
  col_total <- colSums(temp_table)
  temp_table <- temp_table %>% 
    select(names(col_total)[col_total > 0])
  temp <- suppressWarnings(chisq.test(as.matrix(temp_table)))
  tryCatch(mote_temp <- v.chi.sq(x2 = temp$statistic, n = sum(temp_table), 
                        r = nrow(temp_table), c = ncol(temp_table), 
                        a = .05), 
       warning = function(w) { 
         mote_temp <<- v.chi.sq(x2 = temp$statistic, n = sum(temp_table), 
                        r = nrow(temp_table), c = ncol(temp_table), 
                        a = .05)
         mote_temp$vlow <<- 0
  }
  )
  large_effect$year[i] <- year
  large_effect$v[i] <- mote_temp$v
  large_effect$low[i] <- mote_temp$vlow
  large_effect$high[i] <- mote_temp$vhigh
  large_effect$people[i] <- mote_temp$n
  i <- i + 1
}

large_effect$high[is.na(large_effect$high)] <- 0
large_effect <- 
  large_effect %>% 
  filter(v != Inf)

large_dot <- ggplot(large_effect, aes(year,v)) + 
  geom_point(aes(size = people)) + 
  theme_classic(base_size = 15) + 
  geom_pointrange(aes(ymin = low, ymax = high)) + 
  xlab("Year") + 
  ylab(expression(phi)) + 
  scale_size_continuous(name = "Num Authors")

DF_decade <- DF$large_first_gp %>% 
  mutate(who = "F") %>% 
  bind_rows(
    DF$large_other_gp %>% 
      mutate(who = "O")
  ) %>% 
  mutate(Decade = ifelse(Year < 1990, "1980s", 
                         ifelse(Year < 2000, "1990s", 
                                ifelse(Year < 2010, "2000s", 
                                       ifelse(Year < 2020, "2010s", "2020s"))))) %>% 
  group_by(who, Decade) %>% 
  summarize_all(sum) %>% 
  pivot_longer(cols = -c(who, Decade, Year),
               names_to = "Country", 
               values_to = "Count")

# North America, Africa (combine), NWS Europe, Eastern Asia, Latin America, Rest of Europe, Rest of Asia, Everything Else 

DF_decade$Country_2 <- DF_decade$Country
DF_decade$Country_2 <- gsub(".*Africa.*", "Africa", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Northern Europe|Southern Europe|Western Europe", "NWS Europe", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("South-Eastern Europe|Eastern Europe", "ESE Europe", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Central Asia|South-Eastern Asia|Southern Asia|Western Asia", "Asia", DF_decade$Country_2)
DF_decade$Country_2 <- gsub("Melanesia|Mirconesia|New zealand and Australia|Polynesia", "Other", DF_decade$Country_2)

DF_decade$Country_2 <- factor(DF_decade$Country_2, 
                              levels = c("Africa", "Asia", "Eastern Asia", 
                                         "ESE Europe", 
                                         "Latin America and the Caribbean",
                                         "North America", 
                                         "NWS Europe", "Other"))

DF_decade_sm <- DF_decade %>% 
  group_by(Country_2, Decade, who) %>% 
  summarize(Count = sum(Count), .groups = "keep")

large_author <- ggplot(DF_decade_sm, aes(who, Count, fill = Country_2)) + 
    geom_bar(position="fill", stat="identity", color = "black") + 
  theme_classic(base_size = 15) + 
  facet_grid(~Decade) + 
  xlab("Author Type") + 
  ylab("Percent of Authors") + 
  scale_fill_brewer(name = "Region", palette = "Spectral", drop = FALSE)
```

```{r fig-author-gpe, include = TRUE, fig.cap="A comparison of author affiliation geopolitical regions across decades. F stands for first authors and O stands for other authors.", fig.width=10, fig.height=6}
small_author + ggtitle("10-49 Authors") + #theme(legend.position = "none") +
medium_author + ggtitle("50-99 Authors") + #theme(legend.position = "none") + 
large_author + ggtitle("100 + Authors") + #theme(legend.position = "none") + 
guide_area() + 
plot_layout(
  ncol = 2,
  nrow = 2, 
  guides = "collect")

ggsave("figure/figure_7_author_gpe.png", width = 10, height = 6, units = "in")
```

```{r fig-effect-gpe, include = TRUE, fig.cap = "Effect size of the differences in representation for UN Regions for author affiliations in big-team science papers by year. Larger dots indicate more papers and authors represented in the calculation of effect size.", fig.width=10, fig.height=6}
all_effects <- bind_rows(
  small_effect %>% 
    mutate(type = "Small"),
  medium_effect %>% 
    mutate(type = "Medium"), 
  large_effect %>% 
    mutate(type = "Large") 
) %>% 
  mutate(type = factor(type, levels = c("Small", "Medium", "Large"),
                       labels = c("10-49 Authors", 
                                  "50-99 Authors", 
                                  "100+ Authors"))) %>% 
  mutate(Decade = ifelse(year < 1990, "1980s", 
                         ifelse(year < 2000, "1990s", 
                                ifelse(year < 2010, "2000s", 
                                       ifelse(year < 2020, "2010s", "2020s")))))

ggplot(all_effects %>% 
         arrange(v) %>% 
         mutate(count = 1:nrow(all_effects)) %>% 
         filter(year < 2024),
       aes(year, v)) + 
  facet_wrap(~type) + 
  geom_point(aes(size = people)) +
  geom_linerange(aes(ymin = low, ymax = high), alpha = .5) +
  theme_classic(base_size = 15) +
  theme(legend.position = "none") + 
  xlab("Year of Publication") + 
  ylab("Cramer's V")

ggsave("figure/figure_8_author_effect_gpe.png", width = 10, height = 6, units = "in")
```

Figure \@ref(fig:fig-author-gpe) indicates the percent of authors in
regions. In general, we found the same pattern as the overall analysis
wherein most authors are from Europe and North America. The pattern of
representation is roughly similar for the separation of small, medium,
and large numbers of authors on papers. Across time, the representation
does appear to diversify, with more representation in Asia, Latin
American, and Africa. Figure \@ref(fig:fig-effect-gpe) represents the
size of the differences in first/corresponding authors and other authors
across time and number of authors. The differences in representation are
larger for papers with more authors; however, the effects are non-zero
for many of the comparisons. Encouragingly, over time these effects
appear to diminish in size. One limitation with the calculation of
effect sizes for count data is the sensitivity of the data to sample
size (i.e., $\chi^2$ is upwardly biased by sample size, and $V$ is
calculated based on this value). While we used the inclusion of zero as
our boundary for "significance", the interpretation of the effects is
that most are likely small: $V$ \< .05:
`r apa_num(sum(all_effects$v <.05)/nrow(all_effects)*100)`%, $V$ \< .10:
`r apa_num(sum(all_effects$v < .10)/nrow(all_effects)*100)`%, $V$ \<
.20: `r apa_num(sum(all_effects$v < .20)/nrow(all_effects)*100)`%.

# Discussion

In this investigation, we explored the publication rates, areas, and
researchers involved in big team science publications. Over a
half-million articles were published in nearly 15,000 journals since
1970 that qualified as big team science articles (at least ten authors
and ten different affiliations). The areas of publication were aligned
to cancer and genetics research in medicine and oncology for Health and
Life Sciences, physics and chemistry for the Physical Sciences, and
psychology for the Social Sciences All areas of research show an
explosion in growth in the number of publications and the number of
authors included on manuscripts, replicating previous investigations
into this topic area [@sinatra2015; @wuchty2007; @hunter2008].

Our investigation expands into an exploration of the researchers who
publish in big teams focusing on career length, publication metrics, and
geopolitical affiliation. The number of earlier career scholars is
increasing in publications across the years, indicating that big teams
may be more accessible to different types of individuals, not just
older, more established researchers. This result is especially
interesting given the publish-or-perish model still present in most
institutions, as it may seem that large-scale projects could be a risky
choice for non-permanent researchers. In the authors' experience, big
team projects are often quite slow to publication, incentives may be low
for non corresponding authors if institutions do not value papers
without lead authorship, and there is no guarantee for publication even
with a large group. However, with a large team the distribution of work
could imply less effort on individual non-leading members, and research
has shown that larger-team publications do receive more citations and
appear to have higher impact [@larivière2015].

The results for the number of publications by big team researchers
mimics the findings from career length, with a smaller effect size. In
general, it appears that there is a decrease in the average number of
publications a researcher has when publishing on a big team science
paper over time. This result is likely attributable to the number of
early career scholars joining projects, but also may support increased
accessibility for individuals to be involved in this type of research.
Globalization, the internet, and the focus on interdisciplinary research
are potentially driving forces behind our results, but, hopefully, the
results also point to a decline in scientific gatekeeping [@lu2007;
@siler2015].

The variability in the types of researchers involved in publications
also decreased across time in most areas of science with a decrease in
variability for career length. As mentioned, an increase in early career
researchers and numbers of publications could explain this effect
mathematically, potentially with other social influences mentioned
above. The variability in the number of publications is decreasing in
the Physical Sciences, mirroring the career length results, but the
opposite effect was found in the Health and Social Sciences. We see no
clear reason why career variability would decrease while the variability
in the number of publications would increase. The effect sizes for
career length were much larger than the effects for number of
publications. One speculation is the increasing requirements for a
competitive faculty role application. Given the limited number of
positions, one potential way to distinguish their application would be a
larger number of publications in their early career [@caplow2017;
@kyvik2003].

The number of geopolitical entities for researcher affiliation is
increasing over time, showing the results of globalization and the
ability to connect across time zones and cultures [@xie2014]. While our
definition of big team science required at least ten different
institutional affiliations, we did not filter papers by geopolitical
region, and thus, a manuscript could rely solely on institutions within
a single country. The Physical Sciences did not show an increase in
diversity of regions represented, however, it could be argued that the
development of large research centers like CERN forced earlier diversity
than other sciences (i.e., because CERN specifically recruited
scientists from sponsoring nations). The Life, Health, and Social
Sciences saw an increase in the number of regions represented with the
highest increase in the Social Sciences. This result likely corresponds
with an increased interest in big team science publications in
psychology [@coles2022; @forscher2022a], and the desire to diversify the
populations represented in psychological research [@henrich2010;
@newson2021].

While publications on the whole are diversifying, we did not yet find
equality in the representation for first/corresponding author spots
versus all other authors. In general, first authors appear to be less
diverse, representing more European and North American authors, while
other authors include more Asian and African authors. These effect sizes
were often small, but the inequality still persists across years, even
if they are slowly decreasing. Diverse teams are more likely to have
papers with stronger "impact" [@freeman2015; @hinnant2012; @jones2008;
@yang2022] with higher citation metrics for more diverse author lists.
The introduction of contributorship models (e.g., CRediT[@allen2019])
will hopefully continue to push these effects down, as they highlight
each individual's contribution to a manuscript.

The limitations for this research are tied to the availability and
curation of the Scopus dataset. While the number of articles analyzed
for this investigation was large, the criteria for inclusion requires
the correct entry of author affiliations, the correct author linkages
for career length and publication rates, and the correctly marked
geopolitical entity. We had planned to analyze educational levels to
determine if the number of student coauthors (i.e., non-terminal degree)
had increased over time; however, this data was mostly blank within the
Scopus archive. Scopus is a carefully curated dataset, but these
limitations must be kept in mind when interpreting the results.
Publication language diversity was not investigated, and a previous
study indicates that the majority of publications in big databases are
in English [@albarillo2014]. Certainly, publications in non-English
languages would improve the statistics on diversity in scientific
publishing - but the English language barrier likely exists regardless
of inclusion in databases [@meneghini2007; @ramírez-castañeda2020].

Big teams have the ability to provide high-impact, important research
within scientific publishing, and this report suggests a promising trend
of increasing numbers of publications that include earlier career and
more diverse scholars. These partnerships introduce new challenges to
collaboration from interpersonal conflict, infrastructure, incentives,
to international political situations [@forscher2022a]. Directed studies
into ways to navigate these situations would be beneficial for policy
makers at institutions, as well as lead teams who organize and complete
these projects. The implications for retention and promotion processes
across a broad span of regions should be explored to improve diversity
with the understanding of the differential impact of incentives for
participating in big team studies.

\newpage

# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

```{=tex}
\endgroup
```
\newpage

# (APPENDIX) Appendix {.unnumbered}

```{r child = "appendix.Rmd"}
```
