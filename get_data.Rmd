---
title: "Get Data"
author: "Erin M. Buchanan"
date: "Last Knitted: `r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r}
library(dplyr)
library(purrr)
library(bib2df)
library(tidyverse)

library(rorcid)
# orcid_auth() run the first time to set up
# copy the bearer number 
# file.edit("~/.Renviron")
# ORCID_TOKEN="numberhere"

library(scholar)
```

## Import the BibTeX File

In this section, we are importing the bibtex file that includes all the papers we are going to use. 

Notes:

  - We used the preprint manuscript for some papers because they had the entire author list, we will update their references manually for the final dataset. 
  - We will have to manually add the names for several papers that used consortium authors. 
  - The pre-reg of this document only examines one paper to ensure code can be run and develop workflow. 

```{r}
bibs <- bib2df("papers.bib")
```

## ORCID

In this section, we will figure out the ORCIDs for each author if possible. 

  - Data is stored in `bibs$AUTHOR` as a list. 
  - Extract that information and loop over the author list. 
  - Because authors will repeat, we need to put this in long format with one row per author and all other information saved. 
  - Next, split author name, so we can look it up with orcid.

```{r}
# get data into long format
long_bib <- bibs %>% unnest_longer(col = AUTHOR)

# remove this nonsense
long_bib$AUTHOR <- gsub("[{}]", "", long_bib$AUTHOR)

# now split the names into last, first middle 
# first split on the comma only 
long_bib <- long_bib %>% separate(col = AUTHOR, sep = ",", 
                                  into = c("last", "first"), 
                                  extra = "merge")

# remove the first space
long_bib$first <- gsub("^ ", "", long_bib$first)

# then split on space
long_bib <- long_bib %>% separate(col = first, sep = " ", 
                                  into = c("first", "middle"),
                                  extra = "merge")

# drop editor column so it is a non-nested DF
long_bib <- long_bib %>% select(-EDITOR)
write.csv(long_bib, "unedited_bib.csv", row.names = F)
```

To make the finalized data:
  
  - Loop over rows and find candidates for ORCIDs.
  - Export the candidate data.
  - Export the bibtex data (done above).
  - A bit of fun manual merging. 

```{r}
# there are going to be a lot of duplicates
# really only need to check them once if exact match
# not perfect exclusion because of symbol differences and middles but ok 
get_id <- long_bib %>% select(last, first, middle, TITLE)
get_id <- get_id %>% filter(!duplicated(get_id[ , c("last", "first")]))

# clean up titles
get_id$TITLE <- gsub("[[:punct:]]", "", get_id$TITLE)
get_id$TITLE <- tolower(get_id$TITLE)

get_id$ORCID <- NA

#for (i in 1:nrow(get_id)){
for (i in 1:10){ #temporary do a small number 
  
  # find possible candidates 
  possibles <- orcid_search(family_name = get_id$last[i], 
                            given_name = get_id$first[i])
  
  # if nrow = 0 then move on 
  
  # if nrow == 1 then figure out if there's a match
  if (nrow(possibles) == 1){
    temp_works <- orcid_works(possibles$orcid) 
    temp_DF <- do.call(bind_rows, temp_works)
    
    if (nrow(temp_DF) > 0){
    temp_DF$title.title.value <- gsub("[[:punct:]]", "", temp_DF$title.title.value) 
    temp_DF$title.title.value <- tolower(temp_DF$title.title.value) 
    temp_DF <- temp_DF %>% 
      filter(temp_DF$title.title.value == get_id$TITLE[i])
    
    id <- unique(na.omit(temp_DF$`source.assertion-origin-orcid.path`))
    
    if(length(id) == 1) { get_id$ORCID[i] <- id }
    if(length(id) > 1) { get_id$ORCID[i] <- list(id) }
    
    }
  }
  
  # if nrow > 1 figure it out which matches
  if (nrow(possibles) > 1){
    temp_works <- orcid_works(possibles$orcid) 
    temp_DF <- do.call(bind_rows, temp_works)
    
    if (nrow(temp_DF) > 0){
    temp_DF$works$title.title.value <- gsub("[[:punct:]]", "", temp_DF$works$title.title.value) 
    temp_DF$works$title.title.value <- tolower(temp_DF$works$title.title.value) 
    temp_DF <- temp_DF %>% 
      filter(temp_DF$works$title.title.value == get_id$TITLE[i])
    
    id <- unique(na.omit(temp_DF$`source.assertion-origin-orcid.path`))
    
    if(length(id) == 1) { get_id$ORCID[i] <- id }
    if(length(id) > 1) { get_id$ORCID[i] <- list(id) }
    
    }
  }
  
  # be nice to api take a break 
  Sys.sleep(runif(1, 3, 5))
  
}

write.csv(get_id, "possible_orc_ids.csv", row.names = F)
```

## Google Scholar

```{r}
# thanks SO for this id for the bad coding on scholar 
p_get_scholar_id <- possibly(get_scholar_id, otherwise = NA_character_)
scholars <- character(nrow(get_id))
for(i in 1:10) {
  scholars[i] <- p_get_scholar_id(last_name = get_id$last[i], 
                         first_name = get_id$first[i])
  
  # be nice to api take a break 
  Sys.sleep(runif(1, 3, 5))
}

get_id$scholar <- scholars

write.csv(get_id, "possible_both_ids.csv", row.names = F)
```

## Get Person Statistics 

```{r}
erin_df <- rorcid::works("0000-0002-9689-4189") %>%
  as_tibble() %>%
  janitor::clean_names() %>%
  dplyr::mutate(created_date_value = anytime::anydate(created_date_value/1000))

table(erin_df$type)

erin_df$title_title_value <- tolower(erin_df$title_title_value)
erin_df$title_title_value <- gsub("[[:punct:]]", "", erin_df$title_title_value)
nrow(erin_df)

# remove real duplicates
temp <- erin_df[!duplicated(erin_df[ , c("type", "title_title_value") ]), ]
nrow(temp)

# combine types
erin_df$our_type <- erin_df$type
erin_df$our_type <- gsub("other|data-set|preprint", "open_science_pubs", erin_df$our_type)

table(erin_df$our_type)

erin_ed <- orcid_educations("0000-0002-9689-4189") %>% 
  as_tibble() %>%
  janitor::clean_names() 

orcid_employments("0000-0002-9689-4189")

```

May need to manually edit some stuff
Figure out how to get information 

Person statistics: 
- Career length: from first pub, from first degree
  `publication_date_year_value` anything 
- Employment levels
- Education levels
- # Of works: separate to total, other/preprint/data-set, journal/book/traditional
- Limitations of this system 

Journal statistics: 
- Which journals are publishing this information
  - make sure preprints we are using also have real journal merged in 
- Types of big team research (social, cognitive)
  - keywords 
- Over time: are things becoming more varied
  - are the publications more varied over time 